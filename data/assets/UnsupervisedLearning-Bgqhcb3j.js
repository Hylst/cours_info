import{r as k,j as e,C as l,a as m,b as u,e as p,R as v}from"./index-jatdNhFh.js";import{a as A,L as E}from"./Layout-CR8zGZt_.js";import{T as I,a as L,b as c,c as d}from"./tabs-DyU7YeQV.js";import{B as i}from"./badge-D3N1h19b.js";import{E as h,Q as x,P as S,a as R}from"./educational-cards-DKc7pKQa.js";import{a as q,b as D,d as P}from"./collapsible-CoiC7cn5.js";import{S as _}from"./search-CUjlPU8U.js";import{G as N}from"./git-branch-C09JVIQv.js";import{S as j,U as T}from"./unified-hero-section-_j3EuOk5.js";import{E as g}from"./eye-CW1j5p4w.js";import{T as F}from"./target-Cgxv7nHm.js";import{C as z}from"./chart-column-D8DiT-jd.js";import{L as W}from"./layers-DwwRhhRs.js";import{A as V,P as U}from"./ProjectsSection-oGiZ5pbo.js";import{N as O}from"./network-xMSqk6VX.js";import{S as B}from"./shield-1LxtYfpT.js";import{H as K}from"./heart-CxBPzBS_.js";import{T as X}from"./trending-up-gTw2Lzr0.js";import{F as H,R as G}from"./ResourcesSection-DBW5mlgk.js";import{B as Q}from"./brain-e1e4SMeD.js";import{Z as Y}from"./zap-Df3zai_1.js";import{C as J}from"./code-B5o97cHw.js";import{B as $}from"./book-open-BGQhZmI6.js";import{C as Z}from"./CourseBreadcrumb-CLjCCpjS.js";import"./circle-check-big-DcUkgBGn.js";import"./circle-alert-Bf4zJKID.js";import"./users-DpOE6_sU.js";import"./lightbulb-D5sQnwCc.js";import"./star-D_bvZ9E6.js";import"./external-link-CTEWBqNU.js";import"./book-eIDimuOF.js";import"./globe-DnXimFjv.js";import"./video-DJZf6Qay.js";const ee=()=>{const[t,r]=k.useState(!1);return e.jsxs("div",{className:"space-y-8",children:[e.jsxs(l,{className:"bg-gradient-to-r from-green-50 to-emerald-50 border-l-4 border-l-green-500",children:[e.jsx(m,{children:e.jsxs(u,{className:"flex items-center gap-3 text-2xl",children:[e.jsx(_,{className:"h-8 w-8 text-green-600"}),"Bienvenue dans l'Apprentissage Non Supervis√©"]})}),e.jsxs(p,{className:"space-y-6",children:[e.jsx("p",{className:"text-lg text-gray-700 leading-relaxed",children:"Imaginez que vous d√©couvrez une nouvelle plan√®te pleine de cr√©atures inconnues. Sans guide ni manuel, vous devez identifier les esp√®ces, leurs habitats, et leurs comportements. C'est exactement ce que fait l'apprentissage non supervis√© ! üåç‚ú®"}),e.jsxs("div",{className:"bg-white p-6 rounded-xl border shadow-sm",children:[e.jsx("h3",{className:"font-semibold mb-4 text-green-800",children:"üéØ Votre Mission d'Explorateur :"}),e.jsxs("div",{className:"grid md:grid-cols-2 gap-4",children:[e.jsxs("div",{className:"flex items-start gap-3",children:[e.jsx(N,{className:"h-5 w-5 text-green-600 mt-1"}),e.jsxs("div",{children:[e.jsx("h4",{className:"font-medium",children:"Clustering"}),e.jsx("p",{className:"text-sm text-gray-600",children:"Regrouper les cr√©atures similaires"})]})]}),e.jsxs("div",{className:"flex items-start gap-3",children:[e.jsx(j,{className:"h-5 w-5 text-green-600 mt-1"}),e.jsxs("div",{children:[e.jsx("h4",{className:"font-medium",children:"R√©duction de dimension"}),e.jsx("p",{className:"text-sm text-gray-600",children:"Simplifier les donn√©es complexes"})]})]}),e.jsxs("div",{className:"flex items-start gap-3",children:[e.jsx(g,{className:"h-5 w-5 text-green-600 mt-1"}),e.jsxs("div",{children:[e.jsx("h4",{className:"font-medium",children:"D√©tection d'anomalies"}),e.jsx("p",{className:"text-sm text-gray-600",children:"Rep√©rer les sp√©cimens uniques"})]})]}),e.jsxs("div",{className:"flex items-start gap-3",children:[e.jsx(_,{className:"h-5 w-5 text-green-600 mt-1"}),e.jsxs("div",{children:[e.jsx("h4",{className:"font-medium",children:"D√©couverte de motifs"}),e.jsx("p",{className:"text-sm text-gray-600",children:"R√©v√©ler les structures cach√©es"})]})]})]})]})]})]}),e.jsx(h,{title:"üìö Analogie : La Biblioth√®que Myst√©rieuse",type:"analogie",children:e.jsxs("div",{className:"space-y-4",children:[e.jsx("p",{children:"Vous entrez dans une immense biblioth√®que o√π tous les livres sont √©parpill√©s au sol, sans √©tiquettes ni classification. Votre mission : organiser cette biblioth√®que !"}),e.jsxs("div",{className:"bg-gradient-to-r from-blue-50 to-green-50 p-6 rounded-xl space-y-4",children:[e.jsxs("div",{className:"grid md:grid-cols-2 gap-6",children:[e.jsxs("div",{children:[e.jsx("h4",{className:"font-semibold text-blue-800 mb-2",children:"üìö Organisation de Biblioth√®que"}),e.jsxs("ul",{className:"space-y-2 text-sm",children:[e.jsxs("li",{children:["‚Ä¢ ",e.jsx("strong",{children:"Clustering"})," : Regrouper par genre (romans, sciences, histoire)"]}),e.jsxs("li",{children:["‚Ä¢ ",e.jsx("strong",{children:"R√©duction"})," : Cr√©er un syst√®me de classification simple"]}),e.jsxs("li",{children:["‚Ä¢ ",e.jsx("strong",{children:"Anomalies"})," : Rep√©rer les livres rares ou endommag√©s"]}),e.jsxs("li",{children:["‚Ä¢ ",e.jsx("strong",{children:"Motifs"})," : D√©couvrir les th√®mes r√©currents"]})]})]}),e.jsxs("div",{children:[e.jsx("h4",{className:"font-semibold text-green-800 mb-2",children:"ü§ñ Apprentissage Non Supervis√©"}),e.jsxs("ul",{className:"space-y-2 text-sm",children:[e.jsxs("li",{children:["‚Ä¢ ",e.jsx("strong",{children:"K-means"})," : Grouper les donn√©es similaires"]}),e.jsxs("li",{children:["‚Ä¢ ",e.jsx("strong",{children:"PCA"})," : Simplifier en gardant l'essentiel"]}),e.jsxs("li",{children:["‚Ä¢ ",e.jsx("strong",{children:"Isolation Forest"})," : D√©tecter les outliers"]}),e.jsxs("li",{children:["‚Ä¢ ",e.jsx("strong",{children:"Association Rules"})," : Trouver les corr√©lations"]})]})]})]}),e.jsx("div",{className:"bg-white p-4 rounded-lg border border-green-200",children:e.jsxs("p",{className:"text-sm text-green-700",children:["üí° ",e.jsx("strong",{children:"Point cl√© :"})," Dans les deux cas, nous devons d√©couvrir l'organisation cach√©e sans conna√Ætre √† l'avance les cat√©gories !"]})})]})]})}),e.jsxs(l,{className:"border-2 border-green-200",children:[e.jsx(m,{children:e.jsx(u,{className:"text-center",children:"L'Univers de l'Apprentissage Non Supervis√©"})}),e.jsx(p,{children:e.jsx("div",{className:"flex justify-center",children:e.jsxs("svg",{width:"700",height:"500",viewBox:"0 0 700 500",className:"max-w-full h-auto",children:[e.jsx("circle",{cx:"350",cy:"250",r:"60",fill:"#f0f9ff",stroke:"#0369a1",strokeWidth:"3"}),e.jsx("text",{x:"350",y:"245",textAnchor:"middle",className:"font-bold",fill:"#0369a1",fontSize:"14",children:"DONN√âES"}),e.jsx("text",{x:"350",y:"260",textAnchor:"middle",className:"text-sm",fill:"#0369a1",fontSize:"12",children:"NON √âTIQUET√âES"}),e.jsxs("g",{children:[e.jsx("rect",{x:"80",y:"80",width:"120",height:"80",rx:"15",fill:"#dcfce7",stroke:"#16a34a",strokeWidth:"2"}),e.jsx("text",{x:"140",y:"110",textAnchor:"middle",className:"font-semibold",fill:"#16a34a",fontSize:"14",children:"CLUSTERING"}),e.jsx("text",{x:"140",y:"130",textAnchor:"middle",className:"text-sm",fill:"#16a34a",fontSize:"11",children:"K-means"}),e.jsx("text",{x:"140",y:"145",textAnchor:"middle",className:"text-sm",fill:"#16a34a",fontSize:"11",children:"Hierarchical"}),e.jsx("circle",{cx:"50",cy:"200",r:"15",fill:"#22c55e",stroke:"#16a34a"}),e.jsx("circle",{cx:"100",cy:"200",r:"15",fill:"#22c55e",stroke:"#16a34a"}),e.jsx("circle",{cx:"140",cy:"200",r:"15",fill:"#22c55e",stroke:"#16a34a"}),e.jsx("circle",{cx:"180",cy:"200",r:"15",fill:"#22c55e",stroke:"#16a34a"}),e.jsx("text",{x:"115",y:"230",textAnchor:"middle",className:"text-xs",fill:"#16a34a",children:"Groupes d√©couverts"})]}),e.jsxs("g",{children:[e.jsx("rect",{x:"500",y:"80",width:"120",height:"80",rx:"15",fill:"#fef3c7",stroke:"#d97706",strokeWidth:"2"}),e.jsx("text",{x:"560",y:"105",textAnchor:"middle",className:"font-semibold",fill:"#d97706",fontSize:"13",children:"R√âDUCTION"}),e.jsx("text",{x:"560",y:"120",textAnchor:"middle",className:"font-semibold",fill:"#d97706",fontSize:"13",children:"DIMENSION"}),e.jsx("text",{x:"560",y:"135",textAnchor:"middle",className:"text-sm",fill:"#d97706",fontSize:"11",children:"PCA"}),e.jsx("text",{x:"560",y:"150",textAnchor:"middle",className:"text-sm",fill:"#d97706",fontSize:"11",children:"t-SNE"}),e.jsx("rect",{x:"520",y:"180",width:"30",height:"20",fill:"#fbbf24",stroke:"#d97706"}),e.jsx("text",{x:"535",y:"195",textAnchor:"middle",className:"text-xs",fill:"white",children:"3D"}),e.jsx("path",{d:"M 550 190 L 580 190",stroke:"#d97706",strokeWidth:"2",markerEnd:"url(#orangeArrow)"}),e.jsx("rect",{x:"590",y:"185",width:"20",height:"10",fill:"#fbbf24",stroke:"#d97706"}),e.jsx("text",{x:"600",y:"193",textAnchor:"middle",className:"text-xs",fill:"white",children:"2D"})]}),e.jsxs("g",{children:[e.jsx("rect",{x:"80",y:"350",width:"120",height:"80",rx:"15",fill:"#fce7f3",stroke:"#be185d",strokeWidth:"2"}),e.jsx("text",{x:"140",y:"375",textAnchor:"middle",className:"font-semibold",fill:"#be185d",fontSize:"13",children:"D√âTECTION"}),e.jsx("text",{x:"140",y:"390",textAnchor:"middle",className:"font-semibold",fill:"#be185d",fontSize:"13",children:"ANOMALIES"}),e.jsx("text",{x:"140",y:"405",textAnchor:"middle",className:"text-sm",fill:"#be185d",fontSize:"11",children:"Isolation Forest"}),e.jsx("text",{x:"140",y:"420",textAnchor:"middle",className:"text-sm",fill:"#be185d",fontSize:"11",children:"One-Class SVM"}),e.jsx("circle",{cx:"60",cy:"320",r:"8",fill:"#ec4899"}),e.jsx("circle",{cx:"100",cy:"325",r:"8",fill:"#ec4899"}),e.jsx("circle",{cx:"140",cy:"318",r:"8",fill:"#ec4899"}),e.jsx("circle",{cx:"180",cy:"322",r:"8",fill:"#ec4899"}),e.jsx("circle",{cx:"210",cy:"300",r:"12",fill:"#dc2626",stroke:"#be185d",strokeWidth:"2"}),e.jsx("text",{x:"225",y:"305",className:"text-xs font-bold",fill:"#dc2626",children:"!"})]}),e.jsxs("g",{children:[e.jsx("rect",{x:"500",y:"350",width:"120",height:"80",rx:"15",fill:"#e0e7ff",stroke:"#4f46e5",strokeWidth:"2"}),e.jsx("text",{x:"560",y:"375",textAnchor:"middle",className:"font-semibold",fill:"#4f46e5",fontSize:"13",children:"R√àGLES"}),e.jsx("text",{x:"560",y:"390",textAnchor:"middle",className:"font-semibold",fill:"#4f46e5",fontSize:"13",children:"ASSOCIATION"}),e.jsx("text",{x:"560",y:"405",textAnchor:"middle",className:"text-sm",fill:"#4f46e5",fontSize:"11",children:"Apriori"}),e.jsx("text",{x:"560",y:"420",textAnchor:"middle",className:"text-sm",fill:"#4f46e5",fontSize:"11",children:"FP-Growth"}),e.jsx("text",{x:"560",y:"310",textAnchor:"middle",className:"text-xs",fill:"#4f46e5",children:"A + B ‚Üí C"}),e.jsx("text",{x:"560",y:"325",textAnchor:"middle",className:"text-xs",fill:"#4f46e5",children:"(Pain + Beurre ‚Üí Confiture)"})]}),e.jsxs("defs",{children:[e.jsx("marker",{id:"greenArrow",markerWidth:"10",markerHeight:"7",refX:"9",refY:"3.5",orient:"auto",children:e.jsx("polygon",{points:"0 0, 10 3.5, 0 7",fill:"#16a34a"})}),e.jsx("marker",{id:"orangeArrow",markerWidth:"10",markerHeight:"7",refX:"9",refY:"3.5",orient:"auto",children:e.jsx("polygon",{points:"0 0, 10 3.5, 0 7",fill:"#d97706"})}),e.jsx("marker",{id:"pinkArrow",markerWidth:"10",markerHeight:"7",refX:"9",refY:"3.5",orient:"auto",children:e.jsx("polygon",{points:"0 0, 10 3.5, 0 7",fill:"#be185d"})}),e.jsx("marker",{id:"blueArrow",markerWidth:"10",markerHeight:"7",refX:"9",refY:"3.5",orient:"auto",children:e.jsx("polygon",{points:"0 0, 10 3.5, 0 7",fill:"#4f46e5"})})]}),e.jsx("path",{d:"M 300 200 Q 220 140 200 140",stroke:"#16a34a",strokeWidth:"2",fill:"none",markerEnd:"url(#greenArrow)"}),e.jsx("path",{d:"M 400 200 Q 480 140 500 140",stroke:"#d97706",strokeWidth:"2",fill:"none",markerEnd:"url(#orangeArrow)"}),e.jsx("path",{d:"M 300 300 Q 220 360 200 380",stroke:"#be185d",strokeWidth:"2",fill:"none",markerEnd:"url(#pinkArrow)"}),e.jsx("path",{d:"M 400 300 Q 480 360 500 380",stroke:"#4f46e5",strokeWidth:"2",fill:"none",markerEnd:"url(#blueArrow)"})]})})})]}),e.jsx(x,{question:"Quelle est la principale diff√©rence entre l'apprentissage supervis√© et non supervis√© ?",options:["L'apprentissage non supervis√© est plus rapide","L'apprentissage non supervis√© n'utilise pas de donn√©es d'entra√Ænement","L'apprentissage non supervis√© ne dispose pas d'√©tiquettes de r√©ponses correctes","L'apprentissage non supervis√© utilise plus d'algorithmes"],correctAnswer:2,explanation:"Exactement ! L'apprentissage non supervis√© travaille avec des donn√©es sans √©tiquettes. Comme un explorateur qui d√©couvre un nouveau territoire sans carte, l'algorithme doit d√©couvrir les structures et motifs cach√©s par lui-m√™me. C'est ce qui rend cette approche si fascinante et parfois impr√©visible !",difficulty:"facile"}),e.jsxs(q,{open:t,onOpenChange:r,children:[e.jsx(D,{className:"w-full",children:e.jsx(l,{className:"hover:shadow-lg transition-all duration-300 cursor-pointer",children:e.jsx(m,{children:e.jsxs(u,{className:"flex items-center justify-between",children:[e.jsx("span",{className:"flex items-center gap-2",children:"üåü Applications R√©volutionnaires de l'Apprentissage Non Supervis√©"}),e.jsx(A,{className:`h-5 w-5 transition-transform ${t?"rotate-180":""}`})]})})})}),e.jsx(P,{children:e.jsx(l,{className:"mt-2 bg-gradient-to-r from-indigo-50 to-purple-50",children:e.jsxs(p,{className:"pt-6 space-y-4",children:[e.jsxs("div",{className:"grid md:grid-cols-2 gap-6",children:[e.jsxs("div",{children:[e.jsx("h4",{className:"font-semibold text-indigo-800 mb-3",children:"üè• R√©volutions M√©dicales"}),e.jsxs("div",{className:"space-y-3",children:[e.jsxs("div",{className:"border-l-4 border-indigo-400 pl-4",children:[e.jsx(i,{className:"mb-1 bg-indigo-100 text-indigo-800",children:"Diagnostic"}),e.jsx("p",{className:"text-sm",children:"D√©tecter des maladies rares dans les scans m√©dicaux"})]}),e.jsxs("div",{className:"border-l-4 border-indigo-400 pl-4",children:[e.jsx(i,{className:"mb-1 bg-indigo-100 text-indigo-800",children:"G√©nomique"}),e.jsx("p",{className:"text-sm",children:"Identifier des sous-types de cancer par clustering"})]}),e.jsxs("div",{className:"border-l-4 border-indigo-400 pl-4",children:[e.jsx(i,{className:"mb-1 bg-indigo-100 text-indigo-800",children:"√âpid√©miologie"}),e.jsx("p",{className:"text-sm",children:"Traquer la propagation de maladies"})]})]})]}),e.jsxs("div",{children:[e.jsx("h4",{className:"font-semibold text-purple-800 mb-3",children:"üíº Business Intelligence"}),e.jsxs("div",{className:"space-y-3",children:[e.jsxs("div",{className:"border-l-4 border-purple-400 pl-4",children:[e.jsx(i,{className:"mb-1 bg-purple-100 text-purple-800",children:"E-commerce"}),e.jsx("p",{className:"text-sm",children:"Syst√®mes de recommandation personnalis√©s"})]}),e.jsxs("div",{className:"border-l-4 border-purple-400 pl-4",children:[e.jsx(i,{className:"mb-1 bg-purple-100 text-purple-800",children:"Finance"}),e.jsx("p",{className:"text-sm",children:"D√©tection de fraudes et analyses de risque"})]}),e.jsxs("div",{className:"border-l-4 border-purple-400 pl-4",children:[e.jsx(i,{className:"mb-1 bg-purple-100 text-purple-800",children:"Marketing"}),e.jsx("p",{className:"text-sm",children:"Segmentation automatique de client√®le"})]})]})]})]}),e.jsxs("div",{className:"bg-white p-4 rounded-lg border-2 border-dashed border-indigo-300",children:[e.jsx("h4",{className:"font-semibold text-indigo-800 mb-2",children:"üöÄ Cas d'Usage Innovants"}),e.jsxs("div",{className:"grid md:grid-cols-3 gap-3 text-sm",children:[e.jsxs("p",{children:[e.jsx("strong",{children:"üéµ Spotify :"})," Clustering pour cr√©er des playlists automatiques"]}),e.jsxs("p",{children:[e.jsx("strong",{children:"üõ°Ô∏è Cybers√©curit√© :"})," D√©tection d'intrusions par analyse comportementale"]}),e.jsxs("p",{children:[e.jsx("strong",{children:"üåø √âcologie :"})," Classification automatique d'esp√®ces animales"]})]})]})]})})})]})]})},se=()=>{const[t,r]=k.useState({}),b=o=>{r(y=>({...y,[o]:!y[o]}))};return e.jsxs("div",{className:"space-y-8",children:[e.jsxs(h,{title:"üé≠ L'Art du Clustering : Cr√©er de l'Ordre dans le Chaos",type:"concept",children:[e.jsx("p",{className:"mb-4",children:"Le clustering, c'est comme organiser une soir√©e o√π vous ne connaissez personne ! Vous observez les invit√©s et essayez de deviner qui pourrait bien s'entendre, qui partage les m√™mes centres d'int√©r√™t, et vous cr√©ez des groupes naturels."}),e.jsxs("div",{className:"bg-gradient-to-r from-blue-50 to-indigo-50 p-6 rounded-xl space-y-4",children:[e.jsx("h4",{className:"font-semibold text-indigo-800 mb-3",children:"üéØ Objectifs du Clustering"}),e.jsxs("div",{className:"grid md:grid-cols-2 gap-4",children:[e.jsxs("div",{className:"bg-white p-4 rounded-lg border-l-4 border-blue-400",children:[e.jsx("h5",{className:"font-medium text-blue-800 mb-2",children:"üìä Homog√©n√©it√© Intra-cluster"}),e.jsx("p",{className:"text-sm",children:"Les membres d'un m√™me groupe doivent se ressembler"})]}),e.jsxs("div",{className:"bg-white p-4 rounded-lg border-l-4 border-green-400",children:[e.jsx("h5",{className:"font-medium text-green-800 mb-2",children:"üé≠ H√©t√©rog√©n√©it√© Inter-cluster"}),e.jsx("p",{className:"text-sm",children:"Les groupes doivent √™tre bien distincts les uns des autres"})]}),e.jsxs("div",{className:"bg-white p-4 rounded-lg border-l-4 border-purple-400",children:[e.jsx("h5",{className:"font-medium text-purple-800 mb-2",children:"‚öñÔ∏è √âquilibre des Groupes"}),e.jsx("p",{className:"text-sm",children:"√âviter d'avoir un groupe g√©ant et plein de mini-groupes"})]}),e.jsxs("div",{className:"bg-white p-4 rounded-lg border-l-4 border-orange-400",children:[e.jsx("h5",{className:"font-medium text-orange-800 mb-2",children:"üîç Interpr√©tabilit√©"}),e.jsx("p",{className:"text-sm",children:"Les groupes doivent avoir un sens m√©tier"})]})]})]})]}),e.jsxs(q,{open:t.kmeans,onOpenChange:()=>b("kmeans"),children:[e.jsx(D,{className:"w-full",children:e.jsx(l,{className:"hover:shadow-lg transition-all duration-300 cursor-pointer",children:e.jsx(m,{children:e.jsxs(u,{className:"flex items-center justify-between",children:[e.jsxs("span",{className:"flex items-center gap-2",children:[e.jsx(F,{className:"h-6 w-6 text-blue-600"}),"K-means : Le Champion du Clustering"]}),e.jsx(A,{className:`h-5 w-5 transition-transform ${t.kmeans?"rotate-180":""}`})]})})})}),e.jsx(P,{children:e.jsx(l,{className:"mt-2 bg-gradient-to-r from-blue-50 to-cyan-50",children:e.jsxs(p,{className:"pt-6 space-y-6",children:[e.jsx(h,{title:"üéØ K-means : Le Jeu des Centres de Gravit√©",type:"analogie",children:e.jsxs("div",{className:"space-y-4",children:[e.jsx("p",{children:"Imaginez que vous organisez un festival de musique avec plusieurs sc√®nes. Vous devez placer les sc√®nes pour minimiser la distance totale que les spectateurs doivent parcourir selon leurs go√ªts musicaux !"}),e.jsxs("div",{className:"bg-white p-6 rounded-xl border-2 border-dashed border-blue-400",children:[e.jsx("h4",{className:"font-semibold mb-4 text-center",children:"üéµ Algorithme K-means en Action"}),e.jsxs("div",{className:"grid md:grid-cols-3 gap-4 mb-6",children:[e.jsx("div",{className:"text-center",children:e.jsxs("div",{className:"bg-blue-100 p-4 rounded-lg mb-2",children:[e.jsx("h5",{className:"font-semibold text-blue-800",children:"1. Initialisation"}),e.jsx("p",{className:"text-sm",children:"Placer K sc√®nes au hasard"})]})}),e.jsx("div",{className:"text-center",children:e.jsxs("div",{className:"bg-green-100 p-4 rounded-lg mb-2",children:[e.jsx("h5",{className:"font-semibold text-green-800",children:"2. Affectation"}),e.jsx("p",{className:"text-sm",children:"Chaque fan va √† sa sc√®ne la plus proche"})]})}),e.jsx("div",{className:"text-center",children:e.jsxs("div",{className:"bg-purple-100 p-4 rounded-lg mb-2",children:[e.jsx("h5",{className:"font-semibold text-purple-800",children:"3. Mise √† jour"}),e.jsx("p",{className:"text-sm",children:"D√©placer chaque sc√®ne au centre de ses fans"})]})})]}),e.jsx("div",{className:"flex justify-center mb-4",children:e.jsxs("svg",{width:"500",height:"300",viewBox:"0 0 500 300",className:"max-w-full h-auto",children:[e.jsxs("g",{children:[e.jsx("text",{x:"100",y:"20",textAnchor:"middle",className:"font-semibold",fontSize:"14",children:"It√©ration 1"}),e.jsx("circle",{cx:"60",cy:"50",r:"8",fill:"#dc2626",stroke:"#991b1b",strokeWidth:"2"}),e.jsx("circle",{cx:"140",cy:"80",r:"8",fill:"#2563eb",stroke:"#1d4ed8",strokeWidth:"2"}),e.jsx("circle",{cx:"100",cy:"120",r:"8",fill:"#16a34a",stroke:"#15803d",strokeWidth:"2"}),e.jsx("circle",{cx:"50",cy:"60",r:"3",fill:"#fca5a5"}),e.jsx("circle",{cx:"70",cy:"45",r:"3",fill:"#fca5a5"}),e.jsx("circle",{cx:"45",cy:"70",r:"3",fill:"#fca5a5"}),e.jsx("circle",{cx:"130",cy:"85",r:"3",fill:"#93c5fd"}),e.jsx("circle",{cx:"150",cy:"75",r:"3",fill:"#93c5fd"}),e.jsx("circle",{cx:"135",cy:"95",r:"3",fill:"#93c5fd"}),e.jsx("circle",{cx:"90",cy:"125",r:"3",fill:"#86efac"}),e.jsx("circle",{cx:"110",cy:"115",r:"3",fill:"#86efac"}),e.jsx("circle",{cx:"105",cy:"130",r:"3",fill:"#86efac"})]}),e.jsx("path",{d:"M 200 100 L 240 100",stroke:"#374151",strokeWidth:"2",markerEnd:"url(#arrow)"}),e.jsx("text",{x:"220",y:"95",textAnchor:"middle",className:"text-sm",children:"Optimisation"}),e.jsxs("g",{children:[e.jsx("text",{x:"350",y:"20",textAnchor:"middle",className:"font-semibold",fontSize:"14",children:"Convergence"}),e.jsx("circle",{cx:"305",cy:"58",r:"8",fill:"#dc2626",stroke:"#991b1b",strokeWidth:"2"}),e.jsx("circle",{cx:"385",cy:"78",r:"8",fill:"#2563eb",stroke:"#1d4ed8",strokeWidth:"2"}),e.jsx("circle",{cx:"345",cy:"125",r:"8",fill:"#16a34a",stroke:"#15803d",strokeWidth:"2"}),e.jsx("circle",{cx:"295",cy:"68",r:"3",fill:"#fca5a5"}),e.jsx("circle",{cx:"315",cy:"48",r:"3",fill:"#fca5a5"}),e.jsx("circle",{cx:"290",cy:"75",r:"3",fill:"#fca5a5"}),e.jsx("circle",{cx:"375",cy:"88",r:"3",fill:"#93c5fd"}),e.jsx("circle",{cx:"395",cy:"68",r:"3",fill:"#93c5fd"}),e.jsx("circle",{cx:"380",cy:"95",r:"3",fill:"#93c5fd"}),e.jsx("circle",{cx:"335",cy:"135",r:"3",fill:"#86efac"}),e.jsx("circle",{cx:"355",cy:"115",r:"3",fill:"#86efac"}),e.jsx("circle",{cx:"350",cy:"135",r:"3",fill:"#86efac"}),e.jsx("circle",{cx:"305",cy:"58",r:"25",fill:"none",stroke:"#dc2626",strokeWidth:"1",strokeDasharray:"3,3"}),e.jsx("circle",{cx:"385",cy:"78",r:"25",fill:"none",stroke:"#2563eb",strokeWidth:"1",strokeDasharray:"3,3"}),e.jsx("circle",{cx:"345",cy:"125",r:"25",fill:"none",stroke:"#16a34a",strokeWidth:"1",strokeDasharray:"3,3"})]}),e.jsx("defs",{children:e.jsx("marker",{id:"arrow",markerWidth:"10",markerHeight:"7",refX:"9",refY:"3.5",orient:"auto",children:e.jsx("polygon",{points:"0 0, 10 3.5, 0 7",fill:"#374151"})})})]})}),e.jsx("p",{className:"text-sm text-gray-600 text-center",children:"üîÑ On r√©p√®te jusqu'√† ce que les sc√®nes ne bougent plus !"})]})]})}),e.jsxs("div",{className:"grid md:grid-cols-2 gap-6",children:[e.jsxs("div",{children:[e.jsx("h4",{className:"font-semibold text-blue-800 mb-3",children:"‚úÖ Forces de K-means"}),e.jsxs("div",{className:"space-y-2 text-sm",children:[e.jsxs("div",{className:"bg-green-50 p-3 rounded border-l-4 border-green-400",children:[e.jsx("strong",{children:"üöÄ Rapidit√© :"})," Complexit√© O(n¬∑k¬∑i) tr√®s efficace"]}),e.jsxs("div",{className:"bg-green-50 p-3 rounded border-l-4 border-green-400",children:[e.jsx("strong",{children:"üéØ Simplicit√© :"})," Algorithme intuitif et facile √† impl√©menter"]}),e.jsxs("div",{className:"bg-green-50 p-3 rounded border-l-4 border-green-400",children:[e.jsx("strong",{children:"üìä Scalabilit√© :"})," Fonctionne bien avec de gros datasets"]})]})]}),e.jsxs("div",{children:[e.jsx("h4",{className:"font-semibold text-red-800 mb-3",children:"‚ö†Ô∏è Limitations de K-means"}),e.jsxs("div",{className:"space-y-2 text-sm",children:[e.jsxs("div",{className:"bg-red-50 p-3 rounded border-l-4 border-red-400",children:[e.jsx("strong",{children:"üé≤ Initialisation :"})," Sensible aux centres initiaux"]}),e.jsxs("div",{className:"bg-red-50 p-3 rounded border-l-4 border-red-400",children:[e.jsx("strong",{children:"‚≠ï Formes :"})," Pr√©f√®re les clusters sph√©riques"]}),e.jsxs("div",{className:"bg-red-50 p-3 rounded border-l-4 border-red-400",children:[e.jsx("strong",{children:"üî¢ K fixe :"})," Il faut choisir le nombre de clusters"]})]})]})]})]})})})]}),e.jsx(S,{title:"üå≥ Clustering Hi√©rarchique : L'Arbre G√©n√©alogique des Donn√©es",levels:[{title:"Concept de Base",difficulty:"basic",content:e.jsx("div",{className:"space-y-4",children:e.jsxs(h,{title:"üë®‚Äçüë©‚Äçüëß‚Äçüë¶ L'Analogie de l'Arbre G√©n√©alogique",type:"analogie",children:[e.jsx("p",{className:"mb-4",children:"Imaginez que vous reconstituez l'arbre g√©n√©alogique d'une grande famille en regardant les ressemblances physiques, sans conna√Ætre les liens de parent√© !"}),e.jsxs("div",{className:"bg-amber-50 p-4 rounded-lg",children:[e.jsx("h4",{className:"font-semibold mb-2",children:"üîÑ Deux Approches :"}),e.jsxs("div",{className:"grid md:grid-cols-2 gap-4",children:[e.jsxs("div",{className:"bg-white p-3 rounded border-l-4 border-green-400",children:[e.jsx("strong",{children:"‚¨ÜÔ∏è Agglomerative (Bottom-up) :"}),"Partir des individus et former des familles, puis des clans"]}),e.jsxs("div",{className:"bg-white p-3 rounded border-l-4 border-blue-400",children:[e.jsx("strong",{children:"‚¨áÔ∏è Divisive (Top-down) :"}),"Partir du clan entier et diviser en sous-groupes"]})]})]})]})})},{title:"M√©triques de Distance",difficulty:"intermediate",content:e.jsx("div",{className:"space-y-4",children:e.jsxs("div",{className:"bg-white p-4 rounded-lg border",children:[e.jsx("h4",{className:"font-semibold mb-3",children:'üìè Comment Mesurer la "Famille" ?'}),e.jsxs("div",{className:"space-y-3",children:[e.jsxs("div",{className:"bg-blue-50 p-3 rounded",children:[e.jsx("strong",{children:"Single Linkage :"})," Distance entre les plus proches voisins",e.jsx("p",{className:"text-sm text-gray-600",children:'üë´ "Deux familles sont proches si leurs membres les plus similaires se ressemblent"'})]}),e.jsxs("div",{className:"bg-green-50 p-3 rounded",children:[e.jsx("strong",{children:"Complete Linkage :"})," Distance entre les plus √©loign√©s",e.jsx("p",{className:"text-sm text-gray-600",children:'üë• "Deux familles sont proches si m√™me leurs membres les plus diff√©rents se ressemblent"'})]}),e.jsxs("div",{className:"bg-purple-50 p-3 rounded",children:[e.jsx("strong",{children:"Average Linkage :"})," Distance moyenne entre tous les membres",e.jsx("p",{className:"text-sm text-gray-600",children:'‚öñÔ∏è "On fait la moyenne de toutes les ressemblances"'})]})]})]})})},{title:"Dendrogramme",difficulty:"advanced",content:e.jsx("div",{className:"space-y-4",children:e.jsxs("div",{className:"bg-white p-4 rounded-lg border text-center",children:[e.jsx("h4",{className:"font-semibold mb-4",children:"üå≥ Dendrogramme : L'Histoire du Clustering"}),e.jsxs("svg",{width:"400",height:"250",viewBox:"0 0 400 250",className:"max-w-full h-auto mx-auto",children:[e.jsx("text",{x:"50",y:"240",textAnchor:"middle",className:"text-xs",children:"A"}),e.jsx("text",{x:"100",y:"240",textAnchor:"middle",className:"text-xs",children:"B"}),e.jsx("text",{x:"200",y:"240",textAnchor:"middle",className:"text-xs",children:"C"}),e.jsx("text",{x:"250",y:"240",textAnchor:"middle",className:"text-xs",children:"D"}),e.jsx("text",{x:"350",y:"240",textAnchor:"middle",className:"text-xs",children:"E"}),e.jsx("line",{x1:"50",y1:"230",x2:"50",y2:"200",stroke:"#374151",strokeWidth:"2"}),e.jsx("line",{x1:"100",y1:"230",x2:"100",y2:"200",stroke:"#374151",strokeWidth:"2"}),e.jsx("line",{x1:"200",y1:"230",x2:"200",y2:"180",stroke:"#374151",strokeWidth:"2"}),e.jsx("line",{x1:"250",y1:"230",x2:"250",y2:"180",stroke:"#374151",strokeWidth:"2"}),e.jsx("line",{x1:"350",y1:"230",x2:"350",y2:"120",stroke:"#374151",strokeWidth:"2"}),e.jsx("line",{x1:"50",y1:"200",x2:"100",y2:"200",stroke:"#374151",strokeWidth:"2"}),e.jsx("line",{x1:"200",y1:"180",x2:"250",y2:"180",stroke:"#374151",strokeWidth:"2"}),e.jsx("line",{x1:"75",y1:"200",x2:"75",y2:"150",stroke:"#374151",strokeWidth:"2"}),e.jsx("line",{x1:"225",y1:"180",x2:"225",y2:"150",stroke:"#374151",strokeWidth:"2"}),e.jsx("line",{x1:"75",y1:"150",x2:"225",y2:"150",stroke:"#374151",strokeWidth:"2"}),e.jsx("line",{x1:"150",y1:"150",x2:"150",y2:"120",stroke:"#374151",strokeWidth:"2"}),e.jsx("line",{x1:"150",y1:"120",x2:"350",y2:"120",stroke:"#374151",strokeWidth:"2"}),e.jsx("line",{x1:"250",y1:"120",x2:"250",y2:"80",stroke:"#374151",strokeWidth:"2"}),e.jsx("text",{x:"10",y:"205",className:"text-xs fill-blue-600",children:"Distance: 0.2"}),e.jsx("text",{x:"10",y:"185",className:"text-xs fill-green-600",children:"Distance: 0.3"}),e.jsx("text",{x:"10",y:"155",className:"text-xs fill-purple-600",children:"Distance: 0.5"}),e.jsx("text",{x:"10",y:"125",className:"text-xs fill-orange-600",children:"Distance: 0.8"}),e.jsx("text",{x:"10",y:"85",className:"text-xs fill-red-600",children:"Distance: 1.0"}),e.jsx("line",{x1:"20",y1:"140",x2:"380",y2:"140",stroke:"#dc2626",strokeWidth:"2",strokeDasharray:"5,5"}),e.jsx("text",{x:"380",y:"135",className:"text-sm fill-red-600 font-bold",children:"Coupe ‚Üí 3 clusters"})]}),e.jsx("p",{className:"text-sm text-gray-600 mt-2",children:'üí° En "coupant" le dendrogramme √† diff√©rents niveaux, on obtient diff√©rents nombres de clusters !'})]})})}]}),e.jsx(x,{question:"Vous analysez les habitudes d'achat de clients. K-means groupe les clients A, B, C ensemble, mais vous remarquez que A et C ont des comportements tr√®s diff√©rents, seul B leur ressemble un peu. Quel est probablement le probl√®me ?",options:["Le nombre K de clusters est trop petit","Les donn√©es ne sont pas normalis√©es","K-means force des clusters sph√©riques alors que les vrais groupes ont des formes complexes","L'initialisation des centres √©tait mauvaise"],correctAnswer:2,explanation:"Excellent diagnostic ! K-means suppose que les clusters sont sph√©riques et de taille similaire. Si vos vrais groupes de clients ont des formes allong√©es, en demi-lune, ou tr√®s diff√©rentes en taille, K-means va cr√©er des groupes artificiels. Dans ce cas, des m√©thodes comme DBSCAN ou le clustering spectral seraient plus appropri√©es car elles peuvent d√©couvrir des formes arbitraires !",difficulty:"difficile"}),e.jsx(R,{title:"üõçÔ∏è Segmentation de Client√®le E-commerce",problem:"Une boutique en ligne veut segmenter sa client√®le. Vous avez les donn√©es : √¢ge, revenu annuel, fr√©quence d'achat mensuelle, montant moyen par commande. Impl√©mentez un clustering K-means avec validation par la m√©thode du coude (elbow method) pour trouver le nombre optimal de segments.",solution:`import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.datasets import make_blobs

# Simulation de donn√©es clients
np.random.seed(42)
n_clients = 300

# G√©n√©ration de donn√©es r√©alistes
ages = np.random.normal(35, 12, n_clients)
revenus = np.random.normal(50000, 15000, n_clients)
freq_achat = np.random.poisson(8, n_clients)  # achats par mois
montant_moyen = np.random.gamma(2, 50, n_clients)  # montant moyen

# Cr√©ation du dataset
data = np.column_stack([ages, revenus, freq_achat, montant_moyen])

# Normalisation des donn√©es (crucial pour K-means !)
scaler = StandardScaler()
data_scaled = scaler.fit_transform(data)

def elbow_method(data, max_k=10):
    """M√©thode du coude pour trouver K optimal"""
    sse = []  # Sum of Squared Errors
    K_range = range(1, max_k + 1)
    
    for k in K_range:
        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
        kmeans.fit(data)
        sse.append(kmeans.inertia_)
    
    # Trac√© de la courbe du coude
    plt.figure(figsize=(10, 6))
    plt.plot(K_range, sse, 'bo-')
    plt.xlabel('Nombre de clusters (K)')
    plt.ylabel('Somme des erreurs quadratiques (SSE)')
    plt.title('M√©thode du Coude pour d√©terminer K optimal')
    plt.grid(True)
    plt.show()
    
    return sse

def analyze_clusters(data, labels, feature_names):
    """Analyse des caract√©ristiques de chaque cluster"""
    n_clusters = len(np.unique(labels))
    
    print("\\n=== ANALYSE DES SEGMENTS CLIENTS ===")
    for i in range(n_clusters):
        cluster_data = data[labels == i]
        print(f"\\nüìä SEGMENT {i+1} ({len(cluster_data)} clients):")
        
        for j, feature in enumerate(feature_names):
            mean_val = cluster_data[:, j].mean()
            print(f"  ‚Ä¢ {feature}: {mean_val:.1f}")
        
        # Profil du segment
        age_moy = cluster_data[:, 0].mean()
        revenu_moy = cluster_data[:, 1].mean()
        freq_moy = cluster_data[:, 2].mean()
        montant_moy = cluster_data[:, 3].mean()
        
        if age_moy < 30 and freq_moy > 10:
            print("  üè∑Ô∏è Profil: Jeunes acheteurs fr√©quents")
        elif revenu_moy > 60000 and montant_moy > 80:
            print("  üè∑Ô∏è Profil: Clients premium")
        elif freq_moy < 5:
            print("  üè∑Ô∏è Profil: Acheteurs occasionnels")
        else:
            print("  üè∑Ô∏è Profil: Clients r√©guliers")

# Application de la m√©thode du coude
print("üîç Recherche du nombre optimal de clusters...")
sse_values = elbow_method(data_scaled, max_k=8)

# G√©n√©ralement, on voit un "coude" vers K=3 ou K=4
k_optimal = 4  # √Ä ajuster selon votre courbe

# Application du clustering final
kmeans_final = KMeans(n_clusters=k_optimal, random_state=42, n_init=10)
labels = kmeans_final.fit_predict(data_scaled)

# Analyse des r√©sultats
feature_names = ['√Çge', 'Revenu (‚Ç¨)', 'Freq. achat/mois', 'Montant moyen (‚Ç¨)']
analyze_clusters(data, labels, feature_names)

# Visualisation 2D (√¢ge vs revenu)
plt.figure(figsize=(10, 8))
scatter = plt.scatter(data[:, 0], data[:, 1], c=labels, cmap='viridis', alpha=0.7)
plt.xlabel('√Çge')
plt.ylabel('Revenu annuel (‚Ç¨)')
plt.title('Segmentation de la Client√®le (√Çge vs Revenu)')
plt.colorbar(scatter, label='Segment')

# Ajout des centres de clusters (dans l'espace original)
centers_original = scaler.inverse_transform(kmeans_final.cluster_centers_)
plt.scatter(centers_original[:, 0], centers_original[:, 1], 
           c='red', marker='x', s=200, linewidths=3, label='Centres')
plt.legend()
plt.grid(True, alpha=0.3)
plt.show()

print("\\n‚úÖ Segmentation termin√©e ! Vous pouvez maintenant :")
print("   ‚Ä¢ Adapter vos campagnes marketing par segment")
print("   ‚Ä¢ Personnaliser les recommandations produits")  
print("   ‚Ä¢ Optimiser les strat√©gies de fid√©lisation")`,hints:["N'oubliez pas de normaliser vos donn√©es avant K-means (StandardScaler)","La m√©thode du coude cherche le point o√π la r√©duction d'erreur devient marginale","Pensez √† donner du sens m√©tier √† vos clusters d√©couverts","Visualisez vos r√©sultats pour valider la coh√©rence des groupes"],difficulty:"interm√©diaire",estimatedTime:"35 min"})]})},te=({algorithms:t})=>{const[r,b]=v.useState(0),[o,y]=v.useState(!1),[n,w]=v.useState([]),f=s=>{switch(s){case"Faible":return"bg-green-100 text-green-800";case"Moyenne":return"bg-yellow-100 text-yellow-800";case"√âlev√©e":return"bg-red-100 text-red-800";default:return"bg-gray-100 text-gray-800"}},C=s=>"‚≠ê".repeat(s)+"‚òÜ".repeat(5-s),M=s=>{n.includes(s)?w(n.filter(a=>a!==s)):n.length<3&&w([...n,s])};return e.jsx(l,{className:"w-full border-2 hover:shadow-2xl transition-all duration-500",children:e.jsxs(p,{className:"p-8",children:[e.jsxs("div",{className:"flex items-center justify-between mb-8",children:[e.jsx("h3",{className:"text-2xl font-bold",children:"Comparaison des Algorithmes"}),e.jsx("button",{onClick:()=>y(!o),className:`px-4 py-2 rounded-lg font-medium transition-all duration-300 ${o?"bg-red-600 text-white":"bg-blue-600 text-white"}`,children:o?"Mode normal":"Mode comparaison"})]}),o?e.jsxs("div",{className:"space-y-6",children:[e.jsxs("div",{className:"text-center",children:[e.jsx("p",{className:"text-gray-600 mb-4",children:"S√©lectionnez jusqu'√† 3 algorithmes √† comparer:"}),e.jsx("div",{className:"flex justify-center gap-2 flex-wrap",children:t.map((s,a)=>e.jsx("button",{onClick:()=>M(a),className:`px-4 py-2 rounded-lg text-sm font-medium transition-all duration-300 ${n.includes(a)?"bg-blue-600 text-white":"bg-gray-200 text-gray-700 hover:bg-gray-300"}`,disabled:!n.includes(a)&&n.length>=3,children:s.name},a))})]}),n.length>0&&e.jsx("div",{className:"overflow-x-auto",children:e.jsxs("table",{className:"w-full bg-white rounded-xl shadow-lg",children:[e.jsx("thead",{className:"bg-gray-50",children:e.jsxs("tr",{children:[e.jsx("th",{className:"p-4 text-left",children:"Crit√®re"}),n.map(s=>e.jsx("th",{className:"p-4 text-center",children:t[s].name},s))]})}),e.jsxs("tbody",{children:[e.jsxs("tr",{className:"border-t",children:[e.jsx("td",{className:"p-4 font-medium",children:"Type"}),n.map(s=>e.jsx("td",{className:"p-4 text-center",children:e.jsx(i,{variant:"outline",children:t[s].type})},s))]}),e.jsxs("tr",{className:"border-t",children:[e.jsx("td",{className:"p-4 font-medium",children:"Complexit√©"}),n.map(s=>e.jsx("td",{className:"p-4 text-center",children:e.jsx(i,{className:f(t[s].complexity),children:t[s].complexity})},s))]}),e.jsxs("tr",{className:"border-t",children:[e.jsx("td",{className:"p-4 font-medium",children:"Performance"}),n.map(s=>e.jsx("td",{className:"p-4 text-center",children:C(t[s].performance)},s))]}),e.jsxs("tr",{className:"border-t",children:[e.jsx("td",{className:"p-4 font-medium",children:"Interpr√©tabilit√©"}),n.map(s=>e.jsx("td",{className:"p-4 text-center",children:e.jsx(i,{className:f(t[s].interpretability),children:t[s].interpretability})},s))]})]})]})})]}):e.jsxs(e.Fragment,{children:[e.jsx("div",{className:"grid grid-cols-1 md:grid-cols-3 gap-4 mb-8",children:t.map((s,a)=>e.jsxs("button",{onClick:()=>b(a),className:`p-6 rounded-xl border-2 transition-all duration-300 text-left hover:scale-105 ${r===a?"border-blue-500 bg-blue-50 shadow-xl":"border-gray-200 hover:border-gray-300 hover:shadow-lg"}`,children:[e.jsx("h4",{className:"font-bold text-lg mb-2",children:s.name}),e.jsx(i,{variant:"outline",className:"mb-3",children:s.type}),e.jsxs("div",{className:"space-y-2",children:[e.jsxs("div",{className:"flex items-center justify-between",children:[e.jsx("span",{className:"text-sm text-gray-600",children:"Complexit√©:"}),e.jsx(i,{className:f(s.complexity),children:s.complexity})]}),e.jsxs("div",{className:"flex items-center justify-between",children:[e.jsx("span",{className:"text-sm text-gray-600",children:"Performance:"}),e.jsx("span",{className:"text-sm",children:C(s.performance)})]})]})]},a))}),e.jsxs("div",{className:"bg-gradient-to-r from-blue-50 to-purple-50 p-8 rounded-xl border-2 border-blue-200",children:[e.jsx("h4",{className:"text-2xl font-bold mb-6",children:t[r].name}),e.jsxs("div",{className:"grid grid-cols-1 lg:grid-cols-3 gap-8",children:[e.jsxs("div",{className:"bg-white p-6 rounded-xl shadow-lg",children:[e.jsx("h5",{className:"font-semibold text-green-600 mb-4 text-lg",children:"‚úÖ Avantages"}),e.jsx("ul",{className:"space-y-2",children:t[r].pros.map((s,a)=>e.jsxs("li",{className:"flex items-start gap-2",children:[e.jsx("span",{className:"text-green-500 mt-1",children:"‚Ä¢"}),e.jsx("span",{className:"text-sm",children:s})]},a))})]}),e.jsxs("div",{className:"bg-white p-6 rounded-xl shadow-lg",children:[e.jsx("h5",{className:"font-semibold text-red-600 mb-4 text-lg",children:"‚ùå Inconv√©nients"}),e.jsx("ul",{className:"space-y-2",children:t[r].cons.map((s,a)=>e.jsxs("li",{className:"flex items-start gap-2",children:[e.jsx("span",{className:"text-red-500 mt-1",children:"‚Ä¢"}),e.jsx("span",{className:"text-sm",children:s})]},a))})]}),e.jsxs("div",{className:"bg-white p-6 rounded-xl shadow-lg",children:[e.jsx("h5",{className:"font-semibold text-blue-600 mb-4 text-lg",children:"üéØ Cas d'usage"}),e.jsx("ul",{className:"space-y-2",children:t[r].useCases.map((s,a)=>e.jsxs("li",{className:"flex items-start gap-2",children:[e.jsx("span",{className:"text-blue-500 mt-1",children:"‚Ä¢"}),e.jsx("span",{className:"text-sm",children:s})]},a))})]})]}),e.jsxs("div",{className:"mt-6 grid grid-cols-2 gap-4",children:[e.jsxs("div",{className:"bg-white p-4 rounded-lg",children:[e.jsx("span",{className:"text-sm text-gray-600",children:"Complexit√©: "}),e.jsx(i,{className:f(t[r].complexity),children:t[r].complexity})]}),e.jsxs("div",{className:"bg-white p-4 rounded-lg",children:[e.jsx("span",{className:"text-sm text-gray-600",children:"Interpr√©tabilit√©: "}),e.jsx(i,{className:f(t[r].interpretability),children:t[r].interpretability})]})]})]})]})]})})},re=()=>{const t=[{name:"PCA",type:"Analyse en Composantes Principales",pros:["Rapide et efficace","Interpr√©table","R√©duit le bruit","Pr√©serve la variance"],cons:["Lin√©aire uniquement","Perte d'information","Sensible √† l'√©chelle","Difficile avec donn√©es non-lin√©aires"],useCases:["Compression d'images","Visualisation de donn√©es","R√©duction de bruit","Feature engineering"],complexity:"Faible",interpretability:"√âlev√©e",performance:4},{name:"t-SNE",type:"t-Distributed Stochastic Neighbor Embedding",pros:["Excellente visualisation","Pr√©serve structure locale","R√©v√®le clusters cach√©s","Flexible"],cons:["Tr√®s lent","Non d√©terministe","Pas de projection inverse","Hyperparam√®tres sensibles"],useCases:["Visualisation haute dimension","Exploration de donn√©es","D√©tection de patterns","Analyse de clusters"],complexity:"√âlev√©e",interpretability:"Moyenne",performance:3},{name:"UMAP",type:"Uniform Manifold Approximation and Projection",pros:["Plus rapide que t-SNE","Pr√©serve structure globale","Projection inverse possible","Scalable"],cons:["Hyperparam√®tres complexes","Moins mature","R√©sultats variables","Th√©orie complexe"],useCases:["Visualisation de donn√©es","Preprocessing ML","Analyse de topologie","Donn√©es biologiques"],complexity:"√âlev√©e",interpretability:"Moyenne",performance:4},{name:"ICA",type:"Independent Component Analysis",pros:["S√©pare sources ind√©pendantes","Robuste au bruit","Applications sp√©cialis√©es","Th√©orie solide"],cons:["Hypoth√®ses strictes","Sensible √† l'ordre","Interpr√©tation difficile","Applications limit√©es"],useCases:["S√©paration de signaux","Preprocessing audio","Analyse de donn√©es financi√®res","Neuroimagerie"],complexity:"Moyenne",interpretability:"Faible",performance:3}],r=[{title:"Concepts de base",difficulty:"basic",content:e.jsxs("div",{className:"space-y-4",children:[e.jsx("p",{children:"La r√©duction de dimensionnalit√© consiste √† transformer des donn√©es haute dimension en repr√©sentation plus simple."}),e.jsxs("div",{className:"bg-blue-50 p-4 rounded-lg",children:[e.jsx("h4",{className:"font-semibold mb-2",children:"Pourquoi r√©duire les dimensions ?"}),e.jsxs("ul",{className:"text-sm space-y-1",children:[e.jsxs("li",{children:["‚Ä¢ ",e.jsx("strong",{children:"Visualisation :"})," Impossible de visualiser plus de 3 dimensions"]}),e.jsxs("li",{children:["‚Ä¢ ",e.jsx("strong",{children:"Calcul :"})," Moins de variables = calculs plus rapides"]}),e.jsxs("li",{children:["‚Ä¢ ",e.jsx("strong",{children:"Stockage :"})," R√©duction de l'espace m√©moire n√©cessaire"]}),e.jsxs("li",{children:["‚Ä¢ ",e.jsx("strong",{children:"Bruit :"})," √âlimination des variables non informatives"]})]})]})]})},{title:"Techniques avanc√©es",difficulty:"intermediate",content:e.jsxs("div",{className:"space-y-4",children:[e.jsx("h4",{className:"font-semibold",children:"Comparaison des approches principales :"}),e.jsxs("div",{className:"grid md:grid-cols-2 gap-4",children:[e.jsxs("div",{className:"bg-green-50 p-4 rounded-lg border",children:[e.jsx("h5",{className:"font-medium text-green-800 mb-2",children:"M√©thodes Lin√©aires"}),e.jsxs("ul",{className:"text-sm text-green-700 space-y-1",children:[e.jsx("li",{children:"‚Ä¢ PCA : Maximise la variance expliqu√©e"}),e.jsx("li",{children:"‚Ä¢ ICA : S√©pare les sources ind√©pendantes"}),e.jsx("li",{children:"‚Ä¢ LDA : Maximise la s√©parabilit√© entre classes"})]})]}),e.jsxs("div",{className:"bg-purple-50 p-4 rounded-lg border",children:[e.jsx("h5",{className:"font-medium text-purple-800 mb-2",children:"M√©thodes Non-lin√©aires"}),e.jsxs("ul",{className:"text-sm text-purple-700 space-y-1",children:[e.jsx("li",{children:"‚Ä¢ t-SNE : Pr√©serve les structures locales"}),e.jsx("li",{children:"‚Ä¢ UMAP : √âquilibre local et global"}),e.jsx("li",{children:"‚Ä¢ Autoencoders : Apprentissage de repr√©sentations"})]})]})]})]})},{title:"Applications pratiques",difficulty:"advanced",content:e.jsx("div",{className:"space-y-4",children:e.jsxs("div",{className:"grid md:grid-cols-3 gap-4",children:[e.jsxs("div",{className:"bg-blue-50 p-4 rounded-lg border",children:[e.jsxs("h5",{className:"font-medium text-blue-800 mb-2 flex items-center gap-2",children:[e.jsx(g,{className:"h-4 w-4"}),"Computer Vision"]}),e.jsxs("ul",{className:"text-sm text-blue-700 space-y-1",children:[e.jsx("li",{children:"‚Ä¢ Compression d'images JPEG"}),e.jsx("li",{children:"‚Ä¢ D√©tection de visages (Eigenfaces)"}),e.jsx("li",{children:"‚Ä¢ Preprocessing pour CNN"})]})]}),e.jsxs("div",{className:"bg-red-50 p-4 rounded-lg border",children:[e.jsxs("h5",{className:"font-medium text-red-800 mb-2 flex items-center gap-2",children:[e.jsx(z,{className:"h-4 w-4"}),"Bioinformatique"]}),e.jsxs("ul",{className:"text-sm text-red-700 space-y-1",children:[e.jsx("li",{children:"‚Ä¢ Analyse de donn√©es g√©nomiques"}),e.jsx("li",{children:"‚Ä¢ Visualisation de cellules uniques"}),e.jsx("li",{children:"‚Ä¢ D√©couverte de biomarqueurs"})]})]}),e.jsxs("div",{className:"bg-green-50 p-4 rounded-lg border",children:[e.jsxs("h5",{className:"font-medium text-green-800 mb-2 flex items-center gap-2",children:[e.jsx(W,{className:"h-4 w-4"}),"NLP"]}),e.jsxs("ul",{className:"text-sm text-green-700 space-y-1",children:[e.jsx("li",{children:"‚Ä¢ Word embeddings (Word2Vec)"}),e.jsx("li",{children:"‚Ä¢ Analyse s√©mantique"}),e.jsx("li",{children:"‚Ä¢ Clustering de documents"})]})]})]})})}];return e.jsxs("div",{className:"space-y-8",children:[e.jsxs("h2",{className:"text-3xl font-bold text-center flex items-center justify-center gap-3",children:[e.jsx(j,{className:"h-8 w-8 text-purple-600"}),"R√©duction de Dimensionnalit√©"]}),e.jsx(h,{title:"üéØ Comprendre la r√©duction de dimensionnalit√©",type:"concept",children:e.jsxs("div",{className:"space-y-4",children:[e.jsx("p",{className:"text-gray-700 leading-relaxed",children:"Imaginez que vous essayez de dessiner un cube sur une feuille de papier. Vous devez projeter un objet 3D sur une surface 2D tout en pr√©servant l'information importante. C'est exactement le d√©fi de la r√©duction de dimensionnalit√© !"}),e.jsxs("div",{className:"bg-gradient-to-r from-purple-50 to-pink-50 p-6 rounded-xl",children:[e.jsx("h4",{className:"font-semibold text-purple-800 mb-3",children:"Le dilemme dimensionnel"}),e.jsxs("div",{className:"grid md:grid-cols-2 gap-4",children:[e.jsxs("div",{children:[e.jsx("h5",{className:"font-medium text-purple-700 mb-2",children:"Trop de dimensions üìà"}),e.jsxs("ul",{className:"text-sm text-purple-600 space-y-1",children:[e.jsx("li",{children:"‚Ä¢ Mal√©diction de la dimensionnalit√©"}),e.jsx("li",{children:"‚Ä¢ Calculs exponentiellement lents"}),e.jsx("li",{children:"‚Ä¢ Visualisation impossible"}),e.jsx("li",{children:"‚Ä¢ Overfitting des mod√®les"})]})]}),e.jsxs("div",{children:[e.jsx("h5",{className:"font-medium text-purple-700 mb-2",children:"Juste ce qu'il faut ‚ú®"}),e.jsxs("ul",{className:"text-sm text-purple-600 space-y-1",children:[e.jsx("li",{children:"‚Ä¢ Information essentielle pr√©serv√©e"}),e.jsx("li",{children:"‚Ä¢ Calculs efficaces"}),e.jsx("li",{children:"‚Ä¢ Visualisation possible"}),e.jsx("li",{children:"‚Ä¢ Mod√®les g√©n√©ralisables"})]})]})]})]})]})}),e.jsxs(l,{className:"border-2 border-purple-200",children:[e.jsx(m,{children:e.jsx(u,{className:"text-center",children:"Principe de l'Analyse en Composantes Principales (PCA)"})}),e.jsx(p,{children:e.jsx("div",{className:"flex justify-center",children:e.jsxs("svg",{width:"700",height:"400",viewBox:"0 0 700 400",className:"max-w-full h-auto",children:[e.jsx("line",{x1:"100",y1:"350",x2:"300",y2:"350",stroke:"#6b7280",strokeWidth:"2"}),e.jsx("line",{x1:"100",y1:"350",x2:"100",y2:"150",stroke:"#6b7280",strokeWidth:"2"}),e.jsx("text",{x:"310",y:"355",className:"text-sm",fill:"#6b7280",children:"X1"}),e.jsx("text",{x:"85",y:"140",className:"text-sm",fill:"#6b7280",children:"X2"}),e.jsxs("g",{children:[e.jsx("circle",{cx:"120",cy:"320",r:"4",fill:"#3b82f6"}),e.jsx("circle",{cx:"140",cy:"300",r:"4",fill:"#3b82f6"}),e.jsx("circle",{cx:"160",cy:"280",r:"4",fill:"#3b82f6"}),e.jsx("circle",{cx:"180",cy:"260",r:"4",fill:"#3b82f6"}),e.jsx("circle",{cx:"200",cy:"240",r:"4",fill:"#3b82f6"}),e.jsx("circle",{cx:"220",cy:"220",r:"4",fill:"#3b82f6"}),e.jsx("circle",{cx:"240",cy:"200",r:"4",fill:"#3b82f6"}),e.jsx("circle",{cx:"260",cy:"180",r:"4",fill:"#3b82f6"})]}),e.jsx("line",{x1:"110",y1:"340",x2:"270",y2:"170",stroke:"#dc2626",strokeWidth:"3"}),e.jsx("text",{x:"200",y:"240",className:"text-sm font-semibold",fill:"#dc2626",children:"PC1 (variance max)"}),e.jsx("line",{x1:"160",y1:"300",x2:"220",y2:"240",stroke:"#059669",strokeWidth:"2",strokeDasharray:"5,5"}),e.jsx("text",{x:"170",y:"210",className:"text-sm",fill:"#059669",children:"PC2"}),e.jsxs("g",{stroke:"#dc2626",strokeWidth:"1",strokeDasharray:"2,2",opacity:"0.6",children:[e.jsx("line",{x1:"120",y1:"320",x2:"128",y2:"332"}),e.jsx("line",{x1:"140",y1:"300",x2:"148",y2:"312"}),e.jsx("line",{x1:"160",y1:"280",x2:"168",y2:"292"}),e.jsx("line",{x1:"180",y1:"260",x2:"188",y2:"272"}),e.jsx("line",{x1:"200",y1:"240",x2:"208",y2:"252"}),e.jsx("line",{x1:"220",y1:"220",x2:"228",y2:"232"}),e.jsx("line",{x1:"240",y1:"200",x2:"248",y2:"212"}),e.jsx("line",{x1:"260",y1:"180",x2:"268",y2:"192"})]}),e.jsx("defs",{children:e.jsx("marker",{id:"arrow",markerWidth:"10",markerHeight:"7",refX:"9",refY:"3.5",orient:"auto",children:e.jsx("polygon",{points:"0 0, 10 3.5, 0 7",fill:"#7c3aed"})})}),e.jsx("path",{d:"M 350 250 Q 400 200 450 250",stroke:"#7c3aed",strokeWidth:"3",fill:"none",markerEnd:"url(#arrow)"}),e.jsx("text",{x:"380",y:"220",className:"text-sm font-semibold",fill:"#7c3aed",children:"Transformation PCA"}),e.jsx("line",{x1:"500",y1:"350",x2:"600",y2:"350",stroke:"#dc2626",strokeWidth:"2"}),e.jsx("line",{x1:"500",y1:"350",x2:"500",y2:"250",stroke:"#059669",strokeWidth:"2"}),e.jsx("text",{x:"610",y:"355",className:"text-sm font-semibold",fill:"#dc2626",children:"PC1"}),e.jsx("text",{x:"485",y:"240",className:"text-sm",fill:"#059669",children:"PC2"}),e.jsxs("g",{children:[e.jsx("circle",{cx:"515",cy:"350",r:"4",fill:"#3b82f6"}),e.jsx("circle",{cx:"525",cy:"350",r:"4",fill:"#3b82f6"}),e.jsx("circle",{cx:"535",cy:"350",r:"4",fill:"#3b82f6"}),e.jsx("circle",{cx:"545",cy:"350",r:"4",fill:"#3b82f6"}),e.jsx("circle",{cx:"555",cy:"350",r:"4",fill:"#3b82f6"}),e.jsx("circle",{cx:"565",cy:"350",r:"4",fill:"#3b82f6"}),e.jsx("circle",{cx:"575",cy:"350",r:"4",fill:"#3b82f6"}),e.jsx("circle",{cx:"585",cy:"350",r:"4",fill:"#3b82f6"})]}),e.jsx("rect",{x:"50",y:"50",width:"300",height:"80",rx:"10",fill:"#f9fafb",stroke:"#d1d5db"}),e.jsx("text",{x:"60",y:"70",className:"text-sm font-semibold",fill:"#374151",children:"R√©duction 2D ‚Üí 1D :"}),e.jsx("text",{x:"60",y:"90",className:"text-xs",fill:"#6b7280",children:"1. Trouve la direction de variance maximale (PC1)"}),e.jsx("text",{x:"60",y:"105",className:"text-xs",fill:"#6b7280",children:"2. Projette tous les points sur cette ligne"}),e.jsx("text",{x:"60",y:"120",className:"text-xs",fill:"#6b7280",children:"3. Perte minimale d'information"})]})})})]}),e.jsx(te,{algorithms:t}),e.jsx(S,{title:"Approfondissement : De la th√©orie √† la pratique",levels:r}),e.jsx(x,{question:"Vous analysez un dataset d'images 1000x1000 pixels (1M de dimensions) et voulez cr√©er une visualisation 2D pour explorer les groupes. Quelle approche choisiriez-vous ?",options:["Utiliser PCA directement sur toutes les dimensions","Appliquer d'abord PCA pour r√©duire √† ~50 dimensions, puis t-SNE pour la visualisation 2D","Utiliser uniquement t-SNE sur toutes les dimensions","S√©lectionner manuellement 2 pixels repr√©sentatifs"],correctAnswer:1,explanation:"La strat√©gie optimale est de combiner PCA et t-SNE : PCA d'abord pour √©liminer le bruit et r√©duire drastiquement les dimensions (de 1M √† ~50), puis t-SNE pour cr√©er une visualisation 2D qui pr√©serve la structure locale. t-SNE seul sur 1M de dimensions serait computationnellement prohibitif et PCA seul ne r√©v√©lerait pas les structures non-lin√©aires complexes.",difficulty:"difficile"}),e.jsx(x,{question:"Dans quel contexte la perte d'information due √† la r√©duction de dimensionnalit√© est-elle g√©n√©ralement acceptable ?",options:["Jamais, toute perte d'information est probl√©matique","Quand l'information perdue est principalement du bruit ou des redondances","Seulement pour la visualisation, jamais pour l'analyse","Uniquement avec des donn√©es synth√©tiques"],correctAnswer:1,explanation:"La r√©duction de dimensionnalit√© est b√©n√©fique quand l'information √©limin√©e est principalement du bruit, des redondances ou des variations non pertinentes pour la t√¢che. En fait, supprimer ce 'bruit dimensionnel' am√©liore souvent les performances des mod√®les en √©vitant l'overfitting et en r√©v√©lant les patterns vraiment importants dans les donn√©es.",difficulty:"moyen"})]})},ae=[{icon:e.jsx(z,{className:"h-6 w-6 text-blue-600"}),title:"Segmentation Client",description:"Identification automatique de groupes de clients avec des comportements similaires pour optimiser les strat√©gies marketing.",examples:["Clustering RFM (R√©cence, Fr√©quence, Montant)","Segmentation comportementale e-commerce","Groupes de pr√©f√©rences produits","Personnalisation de campagnes marketing"],industry:"E-commerce",difficulty:"D√©butant",impact:"√âlev√©"},{icon:e.jsx(O,{className:"h-6 w-6 text-green-600"}),title:"Analyse de R√©seaux Sociaux",description:"D√©tection de communaut√©s et d'influenceurs dans les r√©seaux sociaux complexes.",examples:["D√©tection de communaut√©s Twitter","Identification d'influenceurs","Analyse de propagation d'information","D√©tection de bots et faux comptes"],industry:"Social Media",difficulty:"Interm√©diaire",impact:"Moyen"},{icon:e.jsx(g,{className:"h-6 w-6 text-purple-600"}),title:"Computer Vision",description:"Segmentation d'images et d√©tection d'objets sans supervision pr√©alable.",examples:["Segmentation automatique d'images m√©dicales","Clustering de caract√©ristiques visuelles","D√©tection d'objets dans images satellites","Compression intelligente d'images"],industry:"Vision",difficulty:"Avanc√©",impact:"√âlev√©"},{icon:e.jsx(B,{className:"h-6 w-6 text-red-600"}),title:"D√©tection de Fraude",description:"Identification automatique de transactions ou comportements anormaux sans exemples pr√©alables.",examples:["D√©tection de fraudes bancaires","Transactions suspectes en temps r√©el","Comportements utilisateurs anormaux","D√©tection d'intrusions r√©seau"],industry:"S√©curit√©",difficulty:"Avanc√©",impact:"√âlev√©"},{icon:e.jsx(K,{className:"h-6 w-6 text-pink-600"}),title:"Recherche M√©dicale",description:"D√©couverte de nouveaux sous-types de maladies et patterns dans les donn√©es biom√©dicales.",examples:["Classification de sous-types de cancer","Analyse de donn√©es g√©nomiques","D√©couverte de biomarqueurs","Clustering de sympt√¥mes patients"],industry:"Sant√©",difficulty:"Avanc√©",impact:"√âlev√©"},{icon:e.jsx(X,{className:"h-6 w-6 text-orange-600"}),title:"Analyse Financi√®re",description:"Identification de patterns de march√© et groupes d'actifs avec comportements similaires.",examples:["Clustering d'actions par secteur","D√©tection de r√©gimes de march√©","Analyse de corr√©lations cach√©es","Optimisation de portefeuilles"],industry:"Finance",difficulty:"Interm√©diaire",impact:"Moyen"},{icon:e.jsx(H,{className:"h-6 w-6 text-gray-600"}),title:"Maintenance Pr√©dictive",description:"D√©tection d'anomalies dans le fonctionnement des machines industrielles.",examples:["Surveillance d'√©quipements industriels","D√©tection de pannes imminentes","Optimisation de maintenance","Analyse vibrationnelle machines"],industry:"Industrie",difficulty:"Interm√©diaire",impact:"√âlev√©"},{icon:e.jsx(Q,{className:"h-6 w-6 text-indigo-600"}),title:"Recommandation de Contenu",description:"Cr√©ation de syst√®mes de recommandation bas√©s sur les similarit√©s entre utilisateurs ou contenus.",examples:["Recommandations Netflix/Spotify","Suggestions produits e-commerce","Filtrage collaboratif","D√©couverte de contenus similaires"],industry:"Streaming",difficulty:"Interm√©diaire",impact:"√âlev√©"},{icon:e.jsx(Y,{className:"h-6 w-6 text-yellow-600"}),title:"Optimisation √ânerg√©tique",description:"Analyse des patterns de consommation √©nerg√©tique pour optimiser la distribution.",examples:["Clustering de profils de consommation","D√©tection de gaspillages √©nerg√©tiques","Optimisation de smart grids","Pr√©diction de pics de demande"],industry:"√ânergie",difficulty:"Interm√©diaire",impact:"Moyen"}],ie=()=>e.jsx(V,{title:"Applications Concr√®tes de l'Apprentissage Non Supervis√©",applications:ae,description:"L'apprentissage non supervis√© r√©v√®le des structures cach√©es dans les donn√©es, permettant de d√©couvrir des insights pr√©cieux sans avoir besoin d'exemples √©tiquet√©s. Ces techniques transforment des donn√©es brutes en connaissances exploitables."}),ne=[{title:"üõí Segmentation Client E-commerce : Analyse RFM avanc√©e",description:"Analysez le comportement d'achat des clients pour cr√©er des segments marketing pr√©cis.",problem:"Vous disposez d'un dataset de transactions e-commerce avec 100,000 clients sur 2 ans. Cr√©ez un syst√®me de segmentation client sophistiqu√© utilisant l'analyse RFM (R√©cence, Fr√©quence, Montant) enrichie d'autres variables comportementales. Impl√©mentez plusieurs algorithmes de clustering, comparez leurs r√©sultats, et cr√©ez des personas d√©taill√©s pour chaque segment avec des recommandations marketing sp√©cifiques.",solution:`# Solution compl√®te de segmentation client
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import silhouette_score
from sklearn.decomposition import PCA
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

class CustomerSegmentation:
    def __init__(self, data_path=None):
        """
        Classe pour la segmentation client avanc√©e
        """
        self.data = None
        self.rfm_data = None
        self.scaler = StandardScaler()
        self.optimal_clusters = None
        self.cluster_labels = None
        
    def load_and_prepare_data(self, data_path=None):
        """
        Charge et pr√©pare les donn√©es de transactions
        """
        if data_path:
            self.data = pd.read_csv(data_path)
        else:
            # G√©n√©ration de donn√©es synth√©tiques pour d√©monstration
            np.random.seed(42)
            n_customers = 10000
            n_transactions = 50000
            
            # G√©n√©ration de clients avec diff√©rents profils
            customers = []
            for i in range(n_customers):
                customer_type = np.random.choice(['high_value', 'regular', 'occasional', 'churned'], 
                                               p=[0.1, 0.4, 0.4, 0.1])
                
                if customer_type == 'high_value':
                    freq = np.random.poisson(20)
                    avg_amount = np.random.normal(150, 50)
                    recency_days = np.random.exponential(30)
                elif customer_type == 'regular':
                    freq = np.random.poisson(8)
                    avg_amount = np.random.normal(75, 25)
                    recency_days = np.random.exponential(60)
                elif customer_type == 'occasional':
                    freq = np.random.poisson(3)
                    avg_amount = np.random.normal(50, 20)
                    recency_days = np.random.exponential(120)
                else:  # churned
                    freq = np.random.poisson(1)
                    avg_amount = np.random.normal(30, 15)
                    recency_days = np.random.exponential(300)
                
                customers.append({
                    'customer_id': f'C{i:06d}',
                    'frequency': max(1, freq),
                    'avg_amount': max(10, avg_amount),
                    'recency_days': max(1, recency_days),
                    'true_segment': customer_type
                })
            
            # Conversion en DataFrame
            self.data = pd.DataFrame(customers)
            
        return self.data
    
    def calculate_rfm_features(self):
        """
        Calcule les m√©triques RFM et features additionnelles
        """
        # Calcul RFM de base
        self.rfm_data = self.data.copy()
        
        # Ajout de features comportementales avanc√©es
        self.rfm_data['monetary_per_transaction'] = (
            self.rfm_data['avg_amount']
        )
        
        # Score de engagement (fr√©quence vs r√©cence)
        self.rfm_data['engagement_score'] = (
            self.rfm_data['frequency'] / (self.rfm_data['recency_days'] / 30 + 1)
        )
        
        # CLV approximation (Customer Lifetime Value)
        self.rfm_data['clv_estimate'] = (
            self.rfm_data['frequency'] * self.rfm_data['avg_amount'] * 
            (365 / (self.rfm_data['recency_days'] + 1))
        )
        
        # Scores RFM normalis√©s (1-5)
        self.rfm_data['recency_score'] = pd.qcut(
            self.rfm_data['recency_days'], 5, labels=[5,4,3,2,1]
        ).astype(int)
        
        self.rfm_data['frequency_score'] = pd.qcut(
            self.rfm_data['frequency'].rank(method='first'), 5, labels=[1,2,3,4,5]
        ).astype(int)
        
        self.rfm_data['monetary_score'] = pd.qcut(
            self.rfm_data['avg_amount'], 5, labels=[1,2,3,4,5]
        ).astype(int)
        
        # Score RFM combin√©
        self.rfm_data['rfm_score'] = (
            self.rfm_data['recency_score'].astype(str) +
            self.rfm_data['frequency_score'].astype(str) +
            self.rfm_data['monetary_score'].astype(str)
        )
        
        print("Features RFM calcul√©es:")
        print(self.rfm_data[['recency_days', 'frequency', 'avg_amount', 
                            'engagement_score', 'clv_estimate']].describe())
        
        return self.rfm_data
    
    def find_optimal_clusters(self, features, max_k=10):
        """
        Trouve le nombre optimal de clusters avec plusieurs m√©thodes
        """
        # Pr√©paration des donn√©es
        X = self.rfm_data[features].copy()
        X_scaled = self.scaler.fit_transform(X)
        
        # M√©thode du coude
        sse = []
        silhouette_scores = []
        k_range = range(2, max_k + 1)
        
        for k in k_range:
            kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
            kmeans.fit(X_scaled)
            sse.append(kmeans.inertia_)
            silhouette_scores.append(silhouette_score(X_scaled, kmeans.labels_))
        
        # Visualisation
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
        
        # M√©thode du coude
        ax1.plot(k_range, sse, 'bo-')
        ax1.set_xlabel('Nombre de clusters (k)')
        ax1.set_ylabel('Sum of Squared Errors')
        ax1.set_title('M√©thode du Coude')
        ax1.grid(True)
        
        # Score de silhouette
        ax2.plot(k_range, silhouette_scores, 'ro-')
        ax2.set_xlabel('Nombre de clusters (k)')
        ax2.set_ylabel('Score de Silhouette')
        ax2.set_title('Score de Silhouette')
        ax2.grid(True)
        
        plt.tight_layout()
        plt.show()
        
        # Choix optimal bas√© sur silhouette score
        optimal_k = k_range[np.argmax(silhouette_scores)]
        self.optimal_clusters = optimal_k
        
        print(f"Nombre optimal de clusters: {optimal_k}")
        print(f"Score de silhouette: {max(silhouette_scores):.3f}")
        
        return optimal_k, silhouette_scores
    
    def perform_clustering(self, features, n_clusters=None):
        """
        Effectue le clustering avec plusieurs algorithmes
        """
        if n_clusters is None:
            n_clusters = self.optimal_clusters or 4
        
        X = self.rfm_data[features].copy()
        X_scaled = self.scaler.fit_transform(X)
        
        # Diff√©rents algorithmes
        algorithms = {
            'KMeans': KMeans(n_clusters=n_clusters, random_state=42),
            'Agglomerative': AgglomerativeClustering(n_clusters=n_clusters),
            'DBSCAN': DBSCAN(eps=0.5, min_samples=50)
        }
        
        results = {}
        
        for name, algorithm in algorithms.items():
            labels = algorithm.fit_predict(X_scaled)
            
            if len(np.unique(labels)) > 1:  # Si plus d'un cluster
                silhouette = silhouette_score(X_scaled, labels)
                results[name] = {
                    'labels': labels,
                    'silhouette': silhouette,
                    'n_clusters': len(np.unique(labels))
                }
                print(f"{name}: {len(np.unique(labels))} clusters, "
                      f"Silhouette: {silhouette:.3f}")
        
        # Choix du meilleur algorithme
        best_algo = max(results.keys(), key=lambda x: results[x]['silhouette'])
        self.cluster_labels = results[best_algo]['labels']
        
        print(f"Meilleur algorithme: {best_algo}")
        
        return results, best_algo
    
    def analyze_segments(self, features):
        """
        Analyse d√©taill√©e des segments cr√©√©s
        """
        # Ajout des labels au dataset
        self.rfm_data['cluster'] = self.cluster_labels
        
        # Analyse par cluster
        cluster_summary = self.rfm_data.groupby('cluster')[features].agg([
            'count', 'mean', 'std', 'min', 'max'
        ]).round(2)
        
        print("R√©sum√© des clusters:")
        print(cluster_summary)
        
        # Cr√©ation de personas
        personas = {}
        for cluster in sorted(self.rfm_data['cluster'].unique()):
            if cluster == -1:  # DBSCAN outliers
                continue
                
            cluster_data = self.rfm_data[self.rfm_data['cluster'] == cluster]
            
            # Caract√©ristiques moyennes
            avg_recency = cluster_data['recency_days'].mean()
            avg_frequency = cluster_data['frequency'].mean()
            avg_monetary = cluster_data['avg_amount'].mean()
            avg_clv = cluster_data['clv_estimate'].mean()
            size = len(cluster_data)
            
            # D√©finition du persona
            if avg_clv > self.rfm_data['clv_estimate'].quantile(0.8):
                persona_name = "Champions"
                description = "Clients les plus pr√©cieux"
                strategy = "Programmes VIP, early access, services premium"
            elif avg_frequency > self.rfm_data['frequency'].quantile(0.6):
                persona_name = "Fid√®les"
                description = "Ach√®tent r√©guli√®rement"
                strategy = "Programmes de fid√©lit√©, recommandations personnalis√©es"
            elif avg_recency > self.rfm_data['recency_days'].quantile(0.7):
                persona_name = "En sommeil"
                description = "N'ont pas achet√© r√©cemment"
                strategy = "Campagnes de r√©activation, offres sp√©ciales"
            else:
                persona_name = "Occasionnels"
                description = "Ach√®tent peu fr√©quemment"
                strategy = "Incitations √† l'achat, √©ducation produit"
            
            personas[cluster] = {
                'name': persona_name,
                'description': description,
                'strategy': strategy,
                'size': size,
                'avg_recency': avg_recency,
                'avg_frequency': avg_frequency,
                'avg_monetary': avg_monetary,
                'avg_clv': avg_clv
            }
        
        return personas
    
    def visualize_segments(self, features):
        """
        Visualisations des segments
        """
        # PCA pour visualisation 2D
        pca = PCA(n_components=2, random_state=42)
        X_scaled = self.scaler.fit_transform(self.rfm_data[features])
        X_pca = pca.fit_transform(X_scaled)
        
        # Cr√©ation des visualisations
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        
        # 1. Scatter plot PCA
        scatter = axes[0,0].scatter(X_pca[:, 0], X_pca[:, 1], 
                                   c=self.cluster_labels, cmap='viridis', alpha=0.6)
        axes[0,0].set_title('Clusters dans l'espace PCA')
        axes[0,0].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)')
        axes[0,0].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)')
        plt.colorbar(scatter, ax=axes[0,0])
        
        # 2. Distribution RFM par cluster
        rfm_cols = ['recency_days', 'frequency', 'avg_amount']
        for i, col in enumerate(rfm_cols):
            if i < 3:
                row, col_idx = (0, 1) if i == 0 else (1, i-1)
                self.rfm_data.boxplot(column=col, by='cluster', ax=axes[row, col_idx])
                axes[row, col_idx].set_title(f'Distribution {col} par cluster')
                axes[row, col_idx].set_xlabel('Cluster')
        
        plt.suptitle('Analyse des Segments Clients', fontsize=16)
        plt.tight_layout()
        plt.show()
        
        # Heatmap des moyennes par cluster
        cluster_means = self.rfm_data.groupby('cluster')[features].mean()
        
        plt.figure(figsize=(12, 8))
        sns.heatmap(cluster_means.T, annot=True, cmap='YlOrRd', 
                   fmt='.2f', cbar_kws={'label': 'Valeur moyenne'})
        plt.title('Profil moyen des segments clients')
        plt.xlabel('Cluster')
        plt.ylabel('Caract√©ristiques')
        plt.tight_layout()
        plt.show()

# Utilisation compl√®te
def main():
    # Initialisation
    segmentation = CustomerSegmentation()
    
    # Chargement des donn√©es
    data = segmentation.load_and_prepare_data()
    
    # Calcul des features RFM
    rfm_data = segmentation.calculate_rfm_features()
    
    # Features pour le clustering
    clustering_features = [
        'recency_days', 'frequency', 'avg_amount', 
        'engagement_score', 'clv_estimate'
    ]
    
    # Recherche du nombre optimal de clusters
    optimal_k, silhouette_scores = segmentation.find_optimal_clusters(
        clustering_features, max_k=8
    )
    
    # Clustering
    results, best_algo = segmentation.perform_clustering(
        clustering_features, n_clusters=optimal_k
    )
    
    # Analyse des segments
    personas = segmentation.analyze_segments(clustering_features)
    
    # Affichage des personas
    print("
=== PERSONAS CLIENTS ===")
    for cluster, persona in personas.items():
        print(f"
Cluster {cluster}: {persona['name']}")
        print(f"Description: {persona['description']}")
        print(f"Taille: {persona['size']} clients")
        print(f"CLV moyenne: {persona['avg_clv']:.2f}‚Ç¨")
        print(f"Strat√©gie: {persona['strategy']}")
    
    # Visualisations
    segmentation.visualize_segments(clustering_features)
    
    return segmentation, personas

# Ex√©cution
if __name__ == "__main__":
    segmentation, personas = main()`,hints:["Explorez d'abord vos donn√©es avec des statistiques descriptives","Cr√©ez des features d√©riv√©es comme l'engagement score et CLV","Utilisez plusieurs m√©thodes pour trouver le nombre optimal de clusters","Comparez diff√©rents algorithmes de clustering (K-means, DBSCAN, Hierarchique)","Validez vos segments avec des m√©triques business et cr√©ez des personas d√©taill√©s"],difficulty:"interm√©diaire",estimatedTime:"180 min",skills:["Clustering","Feature Engineering","Business Intelligence","Data Visualization"],tools:["Python","Scikit-learn","Pandas","Seaborn","Matplotlib"],category:"Business Analytics"},{title:"üîç D√©tection d'Anomalies : Surveillance Syst√®me",description:"Cr√©ez un syst√®me de d√©tection d'anomalies pour surveiller des m√©triques syst√®me en temps r√©el.",problem:"D√©veloppez un syst√®me complet de d√©tection d'anomalies pour surveiller les m√©triques d'un serveur web (CPU, m√©moire, latence, trafic, erreurs). Le syst√®me doit d√©tecter automatiquement les comportements anormaux, classer les anomalies par type et s√©v√©rit√©, et fournir des alertes en temps r√©el. Impl√©mentez plusieurs approches de d√©tection et cr√©ez un dashboard de monitoring.",solution:`# Syst√®me de d√©tection d'anomalies multi-algorithmes
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import IsolationForest
from sklearn.svm import OneClassSVM
from sklearn.cluster import DBSCAN
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.covariance import EllipticEnvelope
import warnings
warnings.filterwarnings('ignore')

class AnomalyDetectionSystem:
    def __init__(self):
        self.scalers = {}
        self.models = {}
        self.thresholds = {}
        self.anomaly_scores = {}
        
    def generate_system_data(self, n_days=30, anomaly_rate=0.05):
        """
        G√©n√®re des donn√©es de m√©triques syst√®me avec anomalies
        """
        np.random.seed(42)
        
        # G√©n√©ration de timestamps
        dates = pd.date_range(
            start='2024-01-01', 
            periods=n_days * 24 * 60,  # 1 point par minute
            freq='1min'
        )
        
        n_points = len(dates)
        
        # Patterns temporels r√©alistes
        hour_of_day = dates.hour
        day_of_week = dates.dayofweek
        
        # CPU Usage (0-100%)
        cpu_base = 30 + 20 * np.sin(2 * np.pi * hour_of_day / 24)  # Cycle journalier
        cpu_base += 5 * (day_of_week < 5)  # Plus √©lev√© en semaine
        cpu_noise = np.random.normal(0, 5, n_points)
        cpu_usage = np.clip(cpu_base + cpu_noise, 0, 100)
        
        # Memory Usage (0-100%)
        memory_base = 45 + 15 * np.sin(2 * np.pi * hour_of_day / 24 + np.pi/4)
        memory_base += 10 * (day_of_week < 5)
        memory_noise = np.random.normal(0, 3, n_points)
        memory_usage = np.clip(memory_base + memory_noise, 0, 100)
        
        # Network Traffic (MB/s)
        traffic_base = 100 + 50 * np.sin(2 * np.pi * hour_of_day / 24)
        traffic_base += 30 * (day_of_week < 5)
        traffic_noise = np.random.exponential(20, n_points)
        network_traffic = np.maximum(traffic_base + traffic_noise, 0)
        
        # Response Time (ms)
        response_base = 200 + 50 * np.sin(2 * np.pi * hour_of_day / 24 + np.pi/3)
        response_base += 100 * (cpu_usage > 80)  # Corr√©lation avec CPU
        response_noise = np.random.gamma(2, 20, n_points)
        response_time = np.maximum(response_base + response_noise, 50)
        
        # Error Rate (%)
        error_base = 0.5 + 0.3 * np.sin(2 * np.pi * hour_of_day / 24)
        error_base += 2 * (response_time > 500)  # Plus d'erreurs si lent
        error_noise = np.random.exponential(0.2, n_points)
        error_rate = np.maximum(error_base + error_noise, 0)
        
        # Cr√©ation du DataFrame
        data = pd.DataFrame({
            'timestamp': dates,
            'cpu_usage': cpu_usage,
            'memory_usage': memory_usage,
            'network_traffic': network_traffic,
            'response_time': response_time,
            'error_rate': error_rate
        })
        
        # Injection d'anomalies
        n_anomalies = int(n_points * anomaly_rate)
        anomaly_indices = np.random.choice(n_points, n_anomalies, replace=False)
        
        data['is_anomaly'] = False
        data.loc[anomaly_indices, 'is_anomaly'] = True
        
        # Types d'anomalies
        for idx in anomaly_indices:
            anomaly_type = np.random.choice([
                'cpu_spike', 'memory_leak', 'network_flood', 
                'response_spike', 'error_burst'
            ])
            
            if anomaly_type == 'cpu_spike':
                data.loc[idx, 'cpu_usage'] = np.random.uniform(90, 100)
            elif anomaly_type == 'memory_leak':
                data.loc[idx, 'memory_usage'] = np.random.uniform(85, 100)
            elif anomaly_type == 'network_flood':
                data.loc[idx, 'network_traffic'] = np.random.uniform(500, 1000)
            elif anomaly_type == 'response_spike':
                data.loc[idx, 'response_time'] = np.random.uniform(2000, 5000)
            elif anomaly_type == 'error_burst':
                data.loc[idx, 'error_rate'] = np.random.uniform(10, 30)
        
        return data
    
    def preprocess_features(self, data):
        """
        Pr√©paration des features pour la d√©tection d'anomalies
        """
        features = data.copy()
        
        # Features temporelles
        features['hour'] = features['timestamp'].dt.hour
        features['day_of_week'] = features['timestamp'].dt.dayofweek
        features['is_weekend'] = (features['day_of_week'] >= 5).astype(int)
        
        # Features d√©riv√©es
        features['cpu_memory_ratio'] = features['cpu_usage'] / (features['memory_usage'] + 1)
        features['traffic_per_response'] = features['network_traffic'] / (features['response_time'] + 1)
        features['error_response_product'] = features['error_rate'] * features['response_time']
        
        # Rolling statistics (tendances)
        for col in ['cpu_usage', 'memory_usage', 'network_traffic', 'response_time']:
            features[f'{col}_rolling_mean'] = features[col].rolling(window=10).mean()
            features[f'{col}_rolling_std'] = features[col].rolling(window=10).std()
            features[f'{col}_deviation'] = (
                features[col] - features[f'{col}_rolling_mean']
            ) / (features[f'{col}_rolling_std'] + 1e-6)
        
        # Suppression des NaN
        features = features.fillna(method='bfill').fillna(method='ffill')
        
        return features
    
    def train_anomaly_detectors(self, train_data):
        """
        Entra√Æne plusieurs algorithmes de d√©tection d'anomalies
        """
        # S√©lection des features pour l'entra√Ænement
        feature_columns = [
            'cpu_usage', 'memory_usage', 'network_traffic', 
            'response_time', 'error_rate', 'hour', 'day_of_week',
            'cpu_memory_ratio', 'traffic_per_response', 'error_response_product'
        ]
        
        X = train_data[feature_columns].copy()
        
        # Normalisation
        self.scalers['main'] = StandardScaler()
        X_scaled = self.scalers['main'].fit_transform(X)
        
        # Mod√®les de d√©tection d'anomalies
        self.models = {
            'isolation_forest': IsolationForest(
                contamination=0.1, random_state=42, n_estimators=200
            ),
            'one_class_svm': OneClassSVM(
                kernel='rbf', gamma='scale', nu=0.1
            ),
            'elliptic_envelope': EllipticEnvelope(
                contamination=0.1, random_state=42
            ),
            'dbscan': DBSCAN(
                eps=0.5, min_samples=10
            )
        }
        
        # Entra√Ænement des mod√®les
        model_scores = {}
        
        for name, model in self.models.items():
            print(f"Entra√Ænement {name}...")
            
            if name == 'dbscan':
                labels = model.fit_predict(X_scaled)
                # DBSCAN: -1 = anomalie, autres = normal
                anomaly_scores = (labels == -1).astype(int)
            else:
                model.fit(X_scaled)
                anomaly_scores = model.decision_function(X_scaled)
            
            model_scores[name] = anomaly_scores
        
        self.anomaly_scores = model_scores
        return model_scores
    
    def detect_anomalies(self, test_data, threshold_percentile=95):
        """
        D√©tecte les anomalies sur nouvelles donn√©es
        """
        feature_columns = [
            'cpu_usage', 'memory_usage', 'network_traffic', 
            'response_time', 'error_rate', 'hour', 'day_of_week',
            'cpu_memory_ratio', 'traffic_per_response', 'error_response_product'
        ]
        
        X = test_data[feature_columns].copy()
        X_scaled = self.scalers['main'].transform(X)
        
        predictions = {}
        consensus_scores = np.zeros(len(X))
        
        for name, model in self.models.items():
            if name == 'dbscan':
                # DBSCAN n√©cessite un re-fit sur nouvelles donn√©es
                labels = model.fit_predict(X_scaled)
                pred = (labels == -1).astype(int)
            else:
                scores = model.decision_function(X_scaled)
                # Seuil bas√© sur les donn√©es d'entra√Ænement
                threshold = np.percentile(self.anomaly_scores[name], threshold_percentile)
                pred = (scores < threshold).astype(int) if name != 'elliptic_envelope' else (scores < 0).astype(int)
            
            predictions[name] = pred
            consensus_scores += pred
        
        # Consensus: anomalie si d√©tect√©e par au moins 2 mod√®les
        consensus_anomalies = (consensus_scores >= 2).astype(int)
        
        return predictions, consensus_anomalies
    
    def classify_anomaly_severity(self, data, anomaly_mask):
        """
        Classifie la s√©v√©rit√© des anomalies d√©tect√©es
        """
        severity_scores = []
        
        for idx in range(len(data)):
            if not anomaly_mask[idx]:
                severity_scores.append(0)  # Normal
                continue
            
            row = data.iloc[idx]
            severity = 0
            
            # Facteurs de s√©v√©rit√©
            if row['cpu_usage'] > 90:
                severity += 3
            elif row['cpu_usage'] > 80:
                severity += 2
            elif row['cpu_usage'] > 70:
                severity += 1
                
            if row['memory_usage'] > 90:
                severity += 3
            elif row['memory_usage'] > 80:
                severity += 2
                
            if row['response_time'] > 2000:
                severity += 3
            elif row['response_time'] > 1000:
                severity += 2
            elif row['response_time'] > 500:
                severity += 1
                
            if row['error_rate'] > 10:
                severity += 3
            elif row['error_rate'] > 5:
                severity += 2
            elif row['error_rate'] > 2:
                severity += 1
            
            # Classification finale
            if severity >= 8:
                severity_level = 'Critical'
            elif severity >= 5:
                severity_level = 'High'
            elif severity >= 3:
                severity_level = 'Medium'
            else:
                severity_level = 'Low'
                
            severity_scores.append(severity_level)
        
        return severity_scores
    
    def generate_alerts(self, data, anomalies, severities):
        """
        G√©n√®re des alertes bas√©es sur les anomalies d√©tect√©es
        """
        alerts = []
        
        for idx in range(len(data)):
            if anomalies[idx]:
                row = data.iloc[idx]
                severity = severities[idx]
                
                # Identification du type d'anomalie principal
                anomaly_type = "Unknown"
                if row['cpu_usage'] > 85:
                    anomaly_type = "High CPU Usage"
                elif row['memory_usage'] > 85:
                    anomaly_type = "High Memory Usage"
                elif row['response_time'] > 1000:
                    anomaly_type = "High Response Time"
                elif row['error_rate'] > 5:
                    anomaly_type = "High Error Rate"
                elif row['network_traffic'] > 400:
                    anomaly_type = "High Network Traffic"
                
                alert = {
                    'timestamp': row['timestamp'],
                    'severity': severity,
                    'type': anomaly_type,
                    'cpu_usage': row['cpu_usage'],
                    'memory_usage': row['memory_usage'],
                    'response_time': row['response_time'],
                    'error_rate': row['error_rate'],
                    'description': f"{anomaly_type} detected at {row['timestamp']}"
                }
                
                alerts.append(alert)
        
        return pd.DataFrame(alerts)
    
    def visualize_results(self, data, anomalies, severities):
        """
        Visualise les r√©sultats de d√©tection d'anomalies
        """
        fig, axes = plt.subplots(3, 2, figsize=(20, 15))
        
        # M√©triques avec anomalies
        metrics = ['cpu_usage', 'memory_usage', 'network_traffic', 
                  'response_time', 'error_rate']
        
        for i, metric in enumerate(metrics):
            row, col = i // 2, i % 2
            if i >= len(axes.flat) - 1:
                break
                
            # Points normaux
            normal_mask = ~anomalies.astype(bool)
            axes[row, col].scatter(
                data.loc[normal_mask, 'timestamp'], 
                data.loc[normal_mask, metric],
                alpha=0.6, s=1, color='blue', label='Normal'
            )
            
            # Points anomalies avec couleur par s√©v√©rit√©
            anomaly_mask = anomalies.astype(bool)
            if anomaly_mask.sum() > 0:
                severity_colors = {
                    'Low': 'yellow', 'Medium': 'orange', 
                    'High': 'red', 'Critical': 'darkred'
                }
                
                for severity, color in severity_colors.items():
                    severity_mask = [s == severity for s in severities]
                    mask = anomaly_mask & severity_mask
                    if mask.sum() > 0:
                        axes[row, col].scatter(
                            data.loc[mask, 'timestamp'],
                            data.loc[mask, metric],
                            alpha=0.8, s=10, color=color, label=f'Anomaly ({severity})'
                        )
            
            axes[row, col].set_title(f'{metric.replace("_", " ").title()}')
            axes[row, col].set_xlabel('Time')
            axes[row, col].legend()
            axes[row, col].tick_params(axis='x', rotation=45)
        
        # Distribution des anomalies par heure
        if anomalies.sum() > 0:
            anomaly_data = data[anomalies.astype(bool)].copy()
            anomaly_data['hour'] = anomaly_data['timestamp'].dt.hour
            hour_counts = anomaly_data['hour'].value_counts().sort_index()
            
            axes[2, 1].bar(hour_counts.index, hour_counts.values, alpha=0.7)
            axes[2, 1].set_title('Distribution des Anomalies par Heure')
            axes[2, 1].set_xlabel('Heure du jour')
            axes[2, 1].set_ylabel('Nombre d'anomalies')
        
        plt.tight_layout()
        plt.show()
        
        # Matrice de corr√©lation des anomalies
        if len(data) > 100:
            correlation_data = data[['cpu_usage', 'memory_usage', 'network_traffic', 
                                   'response_time', 'error_rate']].copy()
            correlation_data['anomaly'] = anomalies
            
            plt.figure(figsize=(10, 8))
            corr_matrix = correlation_data.corr()
            sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0,
                       square=True, linewidths=0.5)
            plt.title('Matrice de Corr√©lation (avec Anomalies)')
            plt.tight_layout()
            plt.show()

def main():
    # Initialisation du syst√®me
    detector = AnomalyDetectionSystem()
    
    # G√©n√©ration des donn√©es
    print("G√©n√©ration des donn√©es syst√®me...")
    data = detector.generate_system_data(n_days=7, anomaly_rate=0.08)
    
    # Pr√©paration des features
    print("Pr√©paration des features...")
    features = detector.preprocess_features(data)
    
    # Division train/test
    split_point = int(len(features) * 0.7)
    train_data = features[:split_point]
    test_data = features[split_point:]
    
    # Entra√Ænement
    print("Entra√Ænement des mod√®les de d√©tection...")
    model_scores = detector.train_anomaly_detectors(train_data)
    
    # D√©tection sur donn√©es test
    print("D√©tection d'anomalies...")
    predictions, consensus = detector.detect_anomalies(test_data)
    
    # Classification de s√©v√©rit√©
    severities = detector.classify_anomaly_severity(test_data, consensus)
    
    # G√©n√©ration d'alertes
    alerts = detector.generate_alerts(test_data, consensus, severities)
    
    # √âvaluation
    true_anomalies = test_data['is_anomaly'].values
    detected_anomalies = consensus
    
    from sklearn.metrics import classification_report, confusion_matrix
    print("
=== √âVALUATION DES PERFORMANCES ===")
    print(classification_report(true_anomalies, detected_anomalies))
    
    print(f"
Nombre d'alertes g√©n√©r√©es: {len(alerts)}")
    if len(alerts) > 0:
        print("Distribution par s√©v√©rit√©:")
        print(alerts['severity'].value_counts())
    
    # Visualisations
    detector.visualize_results(test_data, detected_anomalies, severities)
    
    return detector, alerts

if __name__ == "__main__":
    detector, alerts = main()`,hints:["G√©n√©rez des donn√©es synth√©tiques r√©alistes avec patterns temporels","Cr√©ez des features d√©riv√©es et rolling statistics","Utilisez un ensemble d'algorithmes pour r√©duire les faux positifs","Impl√©mentez un syst√®me de scoring de s√©v√©rit√© bas√© sur le contexte m√©tier","Visualisez les r√©sultats pour valider et am√©liorer votre syst√®me"],difficulty:"avanc√©",estimatedTime:"240 min",skills:["Anomaly Detection","Time Series Analysis","Ensemble Methods","System Monitoring"],tools:["Python","Scikit-learn","Pandas","Matplotlib","Seaborn"],category:"S√©curit√© & Monitoring"}],le=()=>e.jsx(U,{title:"Projets Pratiques en Apprentissage Non Supervis√©",projects:ne,description:"Explorez la puissance de l'apprentissage non supervis√© √† travers ces projets concrets qui couvrent les principales techniques : clustering, d√©tection d'anomalies, et r√©duction de dimensionnalit√©. Chaque projet simule des d√©fis r√©els du monde professionnel."}),oe=[{title:"The Elements of Statistical Learning",description:"R√©f√©rence acad√©mique couvrant en profondeur le clustering, PCA, et autres techniques non supervis√©es avec une approche math√©matique rigoureuse.",type:"book",difficulty:"Avanc√©",language:"Anglais",url:"https://hastie.su.domains/ElemStatLearn/",rating:5,free:!0},{title:"Hands-On Unsupervised Learning",description:"Guide pratique avec impl√©mentations Python pour clustering, r√©duction de dimensionnalit√©, et d√©tection d'anomalies.",type:"book",difficulty:"Interm√©diaire",language:"Anglais",rating:4,free:!1},{title:"CS229: Machine Learning - Unsupervised Learning",description:"Cours de Stanford couvrant K-means, PCA, ICA avec notes d√©taill√©es et exercices pratiques.",type:"video",difficulty:"Interm√©diaire",language:"Anglais",url:"http://cs229.stanford.edu/",rating:5,free:!0},{title:"Scikit-learn Clustering Guide",description:"Documentation compl√®te avec exemples pratiques pour tous les algorithmes de clustering disponibles.",type:"website",difficulty:"D√©butant",language:"Anglais",url:"https://scikit-learn.org/stable/modules/clustering.html",rating:5,free:!0},{title:"UMAP: Uniform Manifold Approximation",description:"Impl√©mentation Python de UMAP pour la r√©duction de dimensionnalit√© non-lin√©aire avec documentation excellente.",type:"code",difficulty:"Interm√©diaire",language:"Python",url:"https://umap-learn.readthedocs.io/",rating:4,free:!0},{title:"Andrew Ng - Unsupervised Learning",description:"Introduction accessible aux concepts fondamentaux avec focus sur les applications pratiques.",type:"video",difficulty:"D√©butant",language:"Anglais",url:"https://www.coursera.org/learn/unsupervised-learning",rating:4,free:!1},{title:"Anomaly Detection: A Survey",description:"Survey acad√©mique complet des techniques de d√©tection d'anomalies avec comparaisons d√©taill√©es.",type:"website",difficulty:"Avanc√©",language:"Anglais",rating:4,free:!0},{title:"PyOD: Python Outlier Detection",description:"Biblioth√®que Python compl√®te pour la d√©tection d'anomalies avec plus de 30 algorithmes impl√©ment√©s.",type:"code",difficulty:"Interm√©diaire",language:"Python",url:"https://pyod.readthedocs.io/",rating:4,free:!0},{title:"t-SNE: Visualizing Data",description:"Article original de van der Maaten expliquant t-SNE avec impl√©mentations et bonnes pratiques.",type:"website",difficulty:"Avanc√©",language:"Anglais",url:"https://lvdmaaten.github.io/tsne/",rating:4,free:!0},{title:"Kaggle Learn: Clustering Course",description:"Cours pratique et interactif sur Kaggle couvrant K-means et clustering hi√©rarchique avec datasets r√©els.",type:"website",difficulty:"D√©butant",language:"Anglais",url:"https://www.kaggle.com/learn/",rating:4,free:!0},{title:"r/MachineLearning",description:"Communaut√© Reddit active avec discussions sur les derni√®res recherches en apprentissage non supervis√©.",type:"community",difficulty:"Interm√©diaire",language:"Anglais",url:"https://reddit.com/r/MachineLearning",rating:4,free:!0},{title:"France Data Science",description:"Communaut√© fran√ßaise de data scientists avec groupes de discussion sur l'apprentissage non supervis√©.",type:"community",difficulty:"Interm√©diaire",language:"Fran√ßais",rating:3,free:!0}],ce=["Commencez toujours par explorer vos donn√©es avec des visualisations","La standardisation des donn√©es est cruciale pour la plupart des algorithmes","Utilisez plusieurs m√©triques d'√©valuation (silhouette, inertie, ARI) pour comparer les r√©sultats","Exp√©rimentez avec diff√©rents hyperparam√®tres - ils ont un impact majeur","Validez vos clusters avec l'expertise m√©tier, pas seulement les m√©triques"],de=["Les r√©sultats peuvent varier selon l'initialisation - testez plusieurs runs","Attention √† la mal√©diction de la dimensionnalit√© avec trop de features","t-SNE peut cr√©er des clusters artificiels - ne sur-interpr√©tez pas","DBSCAN est tr√®s sensible aux param√®tres eps et min_samples","Les algorithmes de clustering assument souvent des formes sph√©riques"],me=["Toujours visualiser vos donn√©es avant et apr√®s clustering","Documentez vos choix d'hyperparam√®tres et leurs justifications","Utilisez la validation crois√©e m√™me en apprentissage non supervis√©","Combinez plusieurs techniques (PCA + clustering) pour de meilleurs r√©sultats","Cr√©ez des m√©triques m√©tier pour √©valuer la qualit√© pratique de vos clusters"],ue=()=>e.jsx(G,{title:"Ressources pour Ma√Ætriser l'Apprentissage Non Supervis√©",resources:oe,tips:ce,warnings:de,bestPractices:me}),pe=()=>{const[t,r]=k.useState("introduction");return e.jsxs("div",{className:"max-w-6xl mx-auto p-6 space-y-8",children:[e.jsx(l,{className:"bg-gradient-to-r from-green-600 to-emerald-600 text-white",children:e.jsxs(m,{className:"text-center",children:[e.jsxs(u,{className:"text-4xl font-bold mb-4 flex items-center justify-center gap-3",children:[e.jsx(_,{className:"h-12 w-12"}),"Apprentissage Non Supervis√©"]}),e.jsx("p",{className:"text-xl text-green-100 max-w-3xl mx-auto",children:"Explorez l'art de d√©couvrir des motifs cach√©s dans les donn√©es, comme un arch√©ologue qui r√©v√®le les secrets d'une civilisation perdue !"}),e.jsxs("div",{className:"flex justify-center gap-3 mt-6 flex-wrap",children:[e.jsxs(i,{className:"bg-white text-green-600 text-sm px-4 py-2",children:[e.jsx(N,{className:"h-4 w-4 mr-2"}),"Clustering"]}),e.jsxs(i,{className:"bg-white text-green-600 text-sm px-4 py-2",children:[e.jsx(j,{className:"h-4 w-4 mr-2"}),"R√©duction de Dimension"]}),e.jsxs(i,{className:"bg-white text-green-600 text-sm px-4 py-2",children:[e.jsx(g,{className:"h-4 w-4 mr-2"}),"D√©tection d'Anomalies"]})]})]})}),e.jsxs(I,{value:t,onValueChange:r,className:"w-full",children:[e.jsxs(L,{className:"grid w-full grid-cols-6 lg:grid-cols-6 h-auto p-1",children:[e.jsxs(c,{value:"introduction",className:"flex flex-col items-center p-3 text-xs lg:text-sm",children:[e.jsx(_,{className:"h-5 w-5 mb-1"}),"Introduction"]}),e.jsxs(c,{value:"clustering",className:"flex flex-col items-center p-3 text-xs lg:text-sm",children:[e.jsx(N,{className:"h-5 w-5 mb-1"}),"Clustering"]}),e.jsxs(c,{value:"reduction",className:"flex flex-col items-center p-3 text-xs lg:text-sm",children:[e.jsx(j,{className:"h-5 w-5 mb-1"}),"R√©duction"]}),e.jsxs(c,{value:"applications",className:"flex flex-col items-center p-3 text-xs lg:text-sm",children:[e.jsx(g,{className:"h-5 w-5 mb-1"}),"Applications"]}),e.jsxs(c,{value:"projects",className:"flex flex-col items-center p-3 text-xs lg:text-sm",children:[e.jsx(J,{className:"h-5 w-5 mb-1"}),"Projets"]}),e.jsxs(c,{value:"resources",className:"flex flex-col items-center p-3 text-xs lg:text-sm",children:[e.jsx($,{className:"h-5 w-5 mb-1"}),"Ressources"]})]}),e.jsx(d,{value:"introduction",className:"mt-8",children:e.jsx(ee,{})}),e.jsx(d,{value:"clustering",className:"mt-8",children:e.jsx(se,{})}),e.jsx(d,{value:"reduction",className:"mt-8",children:e.jsx(re,{})}),e.jsx(d,{value:"applications",className:"mt-8",children:e.jsx(ie,{})}),e.jsx(d,{value:"projects",className:"mt-8",children:e.jsx(le,{})}),e.jsxs(d,{value:"resources",className:"mt-8",children:[e.jsx(ue,{}),e.jsxs("div",{className:"mt-8 space-y-6",children:[e.jsx("h3",{className:"text-2xl font-bold text-center",children:"Quiz Final : Testez vos connaissances !"}),e.jsx(x,{question:"Votre √©quipe doit analyser 1 million de tweets pour identifier les sujets tendances. Quelle approche recommanderiez-vous ?",options:["K-means directement sur le texte brut","TF-IDF + r√©duction PCA + clustering + analyse des centro√Ødes","Classification supervis√©e avec labels manuels","Analyse de fr√©quence des mots uniquement"],correctAnswer:1,explanation:"La meilleure approche combine : 1) TF-IDF pour vectoriser le texte, 2) PCA pour r√©duire la dimensionnalit√© (tweets = haute dimension), 3) clustering pour grouper les sujets similaires, 4) analyse des centro√Ødes pour identifier les mots-cl√©s de chaque sujet. Cette pipeline compl√®te exploite les forces de l'apprentissage non supervis√©.",difficulty:"difficile"}),e.jsx(x,{question:"Dans quels cas l'apprentissage non supervis√© est-il pr√©f√©rable au supervis√© ?",options:["Quand on a beaucoup de donn√©es √©tiquet√©es","Quand on veut d√©couvrir des structures inconnues ou quand l'√©tiquetage est co√ªteux/impossible","Uniquement pour la visualisation de donn√©es","Jamais, le supervis√© est toujours meilleur"],correctAnswer:1,explanation:"L'apprentissage non supervis√© excelle quand : 1) On veut d√©couvrir des patterns inconnus, 2) L'√©tiquetage est trop co√ªteux ou subjectif, 3) On explore des donn√©es pour comprendre leur structure, 4) On fait du preprocessing pour le supervis√©. Il r√©v√®le des insights que l'humain n'aurait pas pens√© √† chercher !",difficulty:"moyen"})]})]})]})]})},He=()=>{const t=[{name:"Machine Learning",href:"/machine-learning"},{name:"Apprentissage non supervis√©",href:"/machine-learning/unsupervised"}];return e.jsx(E,{children:e.jsxs("div",{className:"min-h-screen",children:[e.jsx(T,{variant:"course",title:"Apprentissage Non Supervis√©",description:"Explorez les techniques de clustering, r√©duction de dimensionnalit√© et d√©tection d'anomalies",courseInfo:{level:"Interm√©diaire",duration:"3-5 heures",modules:6}}),e.jsxs("div",{className:"container mx-auto px-4 py-8",children:[e.jsx("div",{className:"mb-6",children:e.jsx(Z,{items:t})}),e.jsx("div",{className:"max-w-6xl mx-auto",children:e.jsx(pe,{})})]})]})})};export{He as default};
